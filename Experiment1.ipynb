{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4e8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4a355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from model.baseline_model import *\n",
    "from trainer import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import robustbench\n",
    "#from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d31627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, train_loader, val_loader = CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e2f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = \"cuda\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0dee4e",
   "metadata": {},
   "source": [
    "# train standard model todo: add more epochs maybe 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbeaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "net_ori = BaseNet().to(device)\n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_ori.parameters(), lr=0.001, momentum=0.9)\n",
    "PATH = './cifar_base.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"NormalBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865ff15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50]\t\n",
      "Epoch [1/50]\t Training Loss: 2.3042824304927034\t lr: 0.001\n",
      "Epoch [1/50]\t Validation Loss: 2.3028613162946097\t lr: 0.001\n",
      "Epoch [1/50]\t\n",
      "Epoch [2/50]\t Training Loss: 2.3023489064267832\t lr: 0.001\n",
      "Epoch [2/50]\t Validation Loss: 2.301627551453023\t lr: 0.001\n",
      "Epoch [2/50]\t\n",
      "Epoch [3/50]\t Training Loss: 2.300663931595395\t lr: 0.001\n",
      "Epoch [3/50]\t Validation Loss: 2.2992500685438326\t lr: 0.001\n",
      "Epoch [3/50]\t\n",
      "Epoch [4/50]\t Training Loss: 2.2961477519910964\t lr: 0.001\n",
      "Epoch [4/50]\t Validation Loss: 2.291310117214541\t lr: 0.001\n",
      "Epoch [4/50]\t\n",
      "Epoch [5/50]\t Training Loss: 2.274019359017882\t lr: 0.001\n",
      "Epoch [5/50]\t Validation Loss: 2.2399823062027555\t lr: 0.001\n",
      "Epoch [5/50]\t\n",
      "Epoch [6/50]\t Training Loss: 2.2003042868641027\t lr: 0.001\n",
      "Epoch [6/50]\t Validation Loss: 2.1800561916979055\t lr: 0.001\n",
      "Epoch [6/50]\t\n",
      "Epoch [7/50]\t Training Loss: 2.163083449044191\t lr: 0.001\n",
      "Epoch [7/50]\t Validation Loss: 2.1463266475291194\t lr: 0.001\n",
      "Epoch [7/50]\t\n",
      "Epoch [8/50]\t Training Loss: 2.1253100228126702\t lr: 0.001\n",
      "Epoch [8/50]\t Validation Loss: 2.0962006019640573\t lr: 0.001\n",
      "Epoch [8/50]\t\n",
      "Epoch [9/50]\t Training Loss: 2.051139748005001\t lr: 0.001\n",
      "Epoch [9/50]\t Validation Loss: 1.9770266677759871\t lr: 0.001\n",
      "Epoch [9/50]\t\n",
      "Epoch [10/50]\t Training Loss: 1.914391109400698\t lr: 0.001\n",
      "Epoch [10/50]\t Validation Loss: 1.8530972215193737\t lr: 0.001\n",
      "Epoch [10/50]\t\n",
      "Epoch [11/50]\t Training Loss: 1.8236508470057222\t lr: 0.001\n",
      "Epoch [11/50]\t Validation Loss: 1.7880869439885587\t lr: 0.001\n",
      "Epoch [11/50]\t\n",
      "Epoch [12/50]\t Training Loss: 1.7522556998235794\t lr: 0.001\n",
      "Epoch [12/50]\t Validation Loss: 1.7075819923907896\t lr: 0.001\n",
      "Epoch [12/50]\t\n",
      "Epoch [13/50]\t Training Loss: 1.6828602686562502\t lr: 0.001\n",
      "Epoch [13/50]\t Validation Loss: 1.672353082065341\t lr: 0.001\n",
      "Epoch [13/50]\t\n",
      "Epoch [14/50]\t Training Loss: 1.6375080441574916\t lr: 0.001\n",
      "Epoch [14/50]\t Validation Loss: 1.6545296711257742\t lr: 0.001\n",
      "Epoch [14/50]\t\n",
      "Epoch [15/50]\t Training Loss: 1.6007662572519248\t lr: 0.001\n",
      "Epoch [15/50]\t Validation Loss: 1.5853986528855335\t lr: 0.001\n",
      "Epoch [15/50]\t\n",
      "Epoch [16/50]\t Training Loss: 1.577567963344057\t lr: 0.001\n",
      "Epoch [16/50]\t Validation Loss: 1.550808523274675\t lr: 0.001\n",
      "Epoch [16/50]\t\n",
      "Epoch [17/50]\t Training Loss: 1.5514581636394686\t lr: 0.001\n",
      "Epoch [17/50]\t Validation Loss: 1.5265640261807019\t lr: 0.001\n",
      "Epoch [17/50]\t\n",
      "Epoch [18/50]\t Training Loss: 1.5222382325955364\t lr: 0.001\n",
      "Epoch [18/50]\t Validation Loss: 1.5039271101166931\t lr: 0.001\n",
      "Epoch [18/50]\t\n",
      "Epoch [19/50]\t Training Loss: 1.5022508034010982\t lr: 0.001\n",
      "Epoch [19/50]\t Validation Loss: 1.4918586151509345\t lr: 0.001\n",
      "Epoch [19/50]\t\n",
      "Epoch [20/50]\t Training Loss: 1.482547050546807\t lr: 0.001\n",
      "Epoch [20/50]\t Validation Loss: 1.50437332105033\t lr: 0.001\n",
      "Epoch [20/50]\t\n",
      "Epoch [21/50]\t Training Loss: 1.4693835248117861\t lr: 0.001\n",
      "Epoch [21/50]\t Validation Loss: 1.4903893274596975\t lr: 0.001\n",
      "Epoch [21/50]\t\n",
      "Epoch [22/50]\t Training Loss: 1.4527933585369373\t lr: 0.001\n",
      "Epoch [22/50]\t Validation Loss: 1.453663646420346\t lr: 0.001\n",
      "Epoch [22/50]\t\n",
      "Epoch [23/50]\t Training Loss: 1.435249810328569\t lr: 0.001\n",
      "Epoch [23/50]\t Validation Loss: 1.427091056787515\t lr: 0.001\n",
      "Epoch [23/50]\t\n",
      "Epoch [24/50]\t Training Loss: 1.4205018413036377\t lr: 0.001\n",
      "Epoch [24/50]\t Validation Loss: 1.4233655537231058\t lr: 0.001\n",
      "Epoch [24/50]\t\n",
      "Epoch [25/50]\t Training Loss: 1.4062768443466147\t lr: 0.001\n",
      "Epoch [25/50]\t Validation Loss: 1.4167882596390158\t lr: 0.001\n",
      "Epoch [25/50]\t\n",
      "Epoch [26/50]\t Training Loss: 1.3907258986207225\t lr: 0.001\n",
      "Epoch [26/50]\t Validation Loss: 1.421531440336493\t lr: 0.001\n",
      "Epoch [26/50]\t\n",
      "Epoch [27/50]\t Training Loss: 1.3790070952661813\t lr: 0.001\n",
      "Epoch [27/50]\t Validation Loss: 1.3809135805202435\t lr: 0.001\n",
      "Epoch [27/50]\t\n",
      "Epoch [28/50]\t Training Loss: 1.368706321472402\t lr: 0.001\n",
      "Epoch [28/50]\t Validation Loss: 1.3914100308961506\t lr: 0.001\n",
      "Epoch [28/50]\t\n",
      "Epoch [29/50]\t Training Loss: 1.353414180333657\t lr: 0.001\n",
      "Epoch [29/50]\t Validation Loss: 1.4276893169065066\t lr: 0.001\n",
      "Epoch [29/50]\t\n",
      "Epoch [30/50]\t Training Loss: 1.3440608328870496\t lr: 0.001\n",
      "Epoch [30/50]\t Validation Loss: 1.3699876718883273\t lr: 0.001\n",
      "Epoch [30/50]\t\n",
      "Epoch [31/50]\t Training Loss: 1.3342535044531079\t lr: 0.001\n",
      "Epoch [31/50]\t Validation Loss: 1.3648804833617392\t lr: 0.001\n",
      "Epoch [31/50]\t\n",
      "Epoch [32/50]\t Training Loss: 1.3299166357425778\t lr: 0.001\n",
      "Epoch [32/50]\t Validation Loss: 1.3386350658875477\t lr: 0.001\n",
      "Epoch [32/50]\t\n",
      "Epoch [33/50]\t Training Loss: 1.3105300788379386\t lr: 0.001\n",
      "Epoch [33/50]\t Validation Loss: 1.3531415387044978\t lr: 0.001\n",
      "Epoch [33/50]\t\n",
      "Epoch [34/50]\t Training Loss: 1.3009034169604405\t lr: 0.001\n",
      "Epoch [34/50]\t Validation Loss: 1.3165868083132972\t lr: 0.001\n",
      "Epoch [34/50]\t\n",
      "Epoch [35/50]\t Training Loss: 1.2885941260915887\t lr: 0.001\n",
      "Epoch [35/50]\t Validation Loss: 1.325734049459047\t lr: 0.001\n",
      "Epoch [35/50]\t\n",
      "Epoch [36/50]\t Training Loss: 1.2831482658605746\t lr: 0.001\n",
      "Epoch [36/50]\t Validation Loss: 1.3102776491189305\t lr: 0.001\n",
      "Epoch [36/50]\t\n",
      "Epoch [37/50]\t Training Loss: 1.2717521172350326\t lr: 0.001\n",
      "Epoch [37/50]\t Validation Loss: 1.3091722636283198\t lr: 0.001\n",
      "Epoch [37/50]\t\n",
      "Epoch [38/50]\t Training Loss: 1.2622101357220994\t lr: 0.001\n",
      "Epoch [38/50]\t Validation Loss: 1.3440843805482117\t lr: 0.001\n",
      "Epoch [38/50]\t\n",
      "Epoch [39/50]\t Training Loss: 1.2514529844074298\t lr: 0.001\n",
      "Epoch [39/50]\t Validation Loss: 1.292669238923471\t lr: 0.001\n",
      "Epoch [39/50]\t\n",
      "Epoch [40/50]\t Training Loss: 1.245907562163175\t lr: 0.001\n",
      "Epoch [40/50]\t Validation Loss: 1.2761672191982028\t lr: 0.001\n",
      "Epoch [40/50]\t\n",
      "Epoch [41/50]\t Training Loss: 1.2347976758961787\t lr: 0.001\n",
      "Epoch [41/50]\t Validation Loss: 1.2820420001126542\t lr: 0.001\n",
      "Epoch [41/50]\t\n",
      "Epoch [42/50]\t Training Loss: 1.2279069216355034\t lr: 0.001\n",
      "Epoch [42/50]\t Validation Loss: 1.2773105479493927\t lr: 0.001\n",
      "Epoch [42/50]\t\n",
      "Epoch [43/50]\t Training Loss: 1.2185784026484965\t lr: 0.001\n",
      "Epoch [43/50]\t Validation Loss: 1.2711887631235244\t lr: 0.001\n",
      "Epoch [43/50]\t\n",
      "Epoch [44/50]\t Training Loss: 1.2141709920695372\t lr: 0.001\n",
      "Epoch [44/50]\t Validation Loss: 1.2893239591695085\t lr: 0.001\n",
      "Epoch [44/50]\t\n",
      "Epoch [45/50]\t Training Loss: 1.1994658789366408\t lr: 0.001\n",
      "Epoch [45/50]\t Validation Loss: 1.2556401430806028\t lr: 0.001\n",
      "Epoch [45/50]\t\n",
      "Epoch [46/50]\t Training Loss: 1.191364003874152\t lr: 0.001\n",
      "Epoch [46/50]\t Validation Loss: 1.254358172416687\t lr: 0.001\n",
      "Epoch [46/50]\t\n",
      "Epoch [47/50]\t Training Loss: 1.1825358648129436\t lr: 0.001\n",
      "Epoch [47/50]\t Validation Loss: 1.2436204099956947\t lr: 0.001\n",
      "Epoch [47/50]\t\n",
      "Epoch [48/50]\t Training Loss: 1.173227259417629\t lr: 0.001\n",
      "Epoch [48/50]\t Validation Loss: 1.2457052288176138\t lr: 0.001\n",
      "Epoch [48/50]\t\n",
      "Epoch [49/50]\t Training Loss: 1.1671711438147307\t lr: 0.001\n",
      "Epoch [49/50]\t Validation Loss: 1.2518166499801828\t lr: 0.001\n",
      "Epoch [49/50]\t\n",
      "Epoch [50/50]\t Training Loss: 1.1606065935795875\t lr: 0.001\n",
      "Epoch [50/50]\t Validation Loss: 1.2312601065333886\t lr: 0.001\n",
      "Epoch [49/50]\t Time Taken: 6.120798766613007 minutes\n"
     ]
    }
   ],
   "source": [
    "train(net_ori, train_loader, train_criterion,val_loader, val_criterion, \n",
    "              optimizer, 50, writer, \n",
    "                 PATH, False, None, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5deda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "#test clean accuray\n",
    "test(val_loader, net_ori)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2950a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = BaseNet().to(device)\n",
    "#test attacks \n",
    "pgd_attack = generate_adv(net_ori, \"pgd\")\n",
    "fgsm_attack = generate_adv(net_ori, \"fgsm\")\n",
    "nifgsm_attack = generate_adv(net_ori, \"nifgsm\")\n",
    "vmifgsm_attack = generate_adv(net_ori, \"vmifgsm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51fbab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_dataset(10000, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf27f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 4.03 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "adv_images_pgd_adv = pgd_attack(images, labels)\n",
    "acc = clean_accuracy(net_ori, adv_images_pgd_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cb7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 7.43 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "adv_images_fgsm_adv = fgsm_attack(images, labels)\n",
    "acc = clean_accuracy(net_ori, adv_images_fgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1292bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 5.60 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "#nifgsm_attack = generate_adv(net, \"nifgsm\")\n",
    "\n",
    "adv_images_nifgsm_adv = nifgsm_attack(images, labels)\n",
    "acc = clean_accuracy(net_ori, adv_images_nifgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f16e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 4.33 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "#vmifgsm_attack = generate_adv(net, \"vmifgsm\")\n",
    "adv_images_vmifgsm_adv =vmifgsm_attack(images, labels)\n",
    "acc = clean_accuracy(net_ori, adv_images_vmifgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb31099",
   "metadata": {},
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeafbdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 5.9848e-02, -5.2299e-02,  2.1430e-01,  3.9787e-02,  2.1806e-01],\n",
      "          [-5.0105e-02, -1.4161e-01, -3.0649e-02,  7.1707e-02,  6.1908e-02],\n",
      "          [-8.4976e-02, -6.6476e-02, -2.0944e-01, -1.3324e-01, -8.4117e-02],\n",
      "          [-7.0177e-03, -1.8230e-01, -5.3974e-02, -1.3035e-01,  2.1496e-02],\n",
      "          [ 2.4488e-01, -4.5639e-02,  3.4719e-02, -5.2099e-02,  1.1870e-01]],\n",
      "\n",
      "         [[ 1.2060e-02, -1.2220e-02,  1.3480e-01, -1.0539e-02,  1.5150e-01],\n",
      "          [-1.0929e-01, -1.1086e-01, -9.1473e-02,  2.9505e-03,  1.0279e-01],\n",
      "          [ 9.7334e-02, -1.1177e-01, -1.7327e-01,  7.1333e-02,  9.2015e-03],\n",
      "          [ 1.2965e-02, -9.0692e-02, -1.2689e-01,  8.6416e-02, -1.2764e-01],\n",
      "          [ 2.6695e-01,  6.7538e-02,  1.2677e-01,  1.7106e-01,  1.2766e-01]],\n",
      "\n",
      "         [[-2.9045e-02, -1.2880e-01,  2.8464e-02,  1.3241e-01,  1.3513e-01],\n",
      "          [ 1.0995e-01, -5.6772e-02, -2.2852e-02,  1.1513e-01, -3.6542e-02],\n",
      "          [ 1.1706e-02, -3.7067e-02, -5.8166e-02, -1.2487e-01, -1.0409e-01],\n",
      "          [-1.6239e-02, -1.6374e-01, -1.0367e-01, -1.0877e-02, -1.3684e-01],\n",
      "          [ 1.9699e-01,  1.4774e-01, -7.3441e-02, -1.5481e-02, -6.8205e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9890e-01, -2.7444e-01, -1.4827e-01, -3.5768e-01, -2.1857e-01],\n",
      "          [-2.3639e-01, -2.4822e-01, -2.9093e-01, -1.2249e-01, -1.5843e-01],\n",
      "          [ 9.6408e-03, -8.2427e-02, -1.1967e-01, -2.3143e-02,  1.1100e-01],\n",
      "          [ 2.8199e-02,  1.8349e-01,  2.5602e-01,  1.8453e-01,  3.7481e-02],\n",
      "          [ 3.0119e-01,  3.4829e-01,  1.8645e-01,  2.1631e-01,  4.3889e-02]],\n",
      "\n",
      "         [[-3.0553e-02, -1.8802e-01, -5.5412e-02, -2.3435e-01, -2.6856e-02],\n",
      "          [-6.1881e-02, -2.8005e-01, -1.9320e-01, -7.2307e-02,  4.1494e-02],\n",
      "          [-1.4882e-01, -1.0117e-01, -7.1668e-03,  4.2482e-02,  1.4855e-01],\n",
      "          [ 2.2263e-01,  3.3019e-01,  2.0654e-01,  3.2670e-01,  1.4701e-01],\n",
      "          [ 1.5957e-01,  1.9649e-01,  2.5581e-01,  2.7791e-01,  1.7408e-01]],\n",
      "\n",
      "         [[ 1.7417e-02,  2.7769e-02, -1.2235e-01, -1.7747e-01, -7.3902e-02],\n",
      "          [-1.4621e-01, -2.7957e-01, -2.0163e-01, -2.1245e-01,  6.7823e-02],\n",
      "          [-2.5097e-04, -1.6907e-01,  5.1492e-02, -2.5343e-02,  1.3530e-02],\n",
      "          [ 1.6615e-03,  1.2959e-01,  9.8875e-02,  9.3492e-03,  9.9850e-02],\n",
      "          [ 8.2550e-02,  1.6705e-01,  1.8799e-01,  2.3303e-01,  4.1724e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8129e-01, -6.7125e-02, -7.1049e-02, -3.9949e-02, -6.2910e-02],\n",
      "          [-6.3122e-02,  2.6497e-02,  1.1652e-01, -2.4078e-02,  2.3705e-02],\n",
      "          [-1.9850e-02,  1.8837e-01,  1.1855e-01,  2.0786e-01,  7.4025e-02],\n",
      "          [-8.8754e-03,  4.0622e-02,  1.7769e-01,  1.1238e-01,  9.1700e-02],\n",
      "          [-2.9348e-03,  9.3335e-02,  2.1555e-01,  1.7704e-01,  9.6761e-02]],\n",
      "\n",
      "         [[-1.3700e-01,  6.8444e-02,  4.2585e-02,  1.7875e-01, -7.1849e-02],\n",
      "          [-8.8417e-02,  1.0713e-01,  1.8070e-01,  1.0140e-01,  1.0709e-01],\n",
      "          [ 1.9604e-02,  7.6209e-02,  1.9136e-01,  2.2059e-01, -1.4645e-02],\n",
      "          [ 2.6930e-02,  4.3304e-02,  8.7910e-02,  7.5590e-02,  7.8766e-02],\n",
      "          [-7.3872e-02,  1.1507e-01,  1.3490e-01, -3.3901e-02, -8.9710e-02]],\n",
      "\n",
      "         [[ 1.5427e-01,  3.3916e-01,  4.0615e-01,  3.3010e-01,  9.8423e-02],\n",
      "          [ 1.2702e-01,  2.5370e-01,  4.1082e-01,  3.6363e-01,  2.8225e-01],\n",
      "          [ 7.1672e-02,  2.9580e-01,  4.4142e-01,  3.4741e-01,  9.0784e-02],\n",
      "          [ 1.4682e-01,  2.2799e-01,  3.2510e-01,  2.4540e-01,  1.6516e-01],\n",
      "          [ 8.2321e-02,  1.6292e-01,  1.2487e-01,  9.1725e-02,  9.7540e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2663e-03, -2.4153e-01, -3.3872e-02, -1.2511e-01, -2.0533e-01],\n",
      "          [-7.2496e-02, -9.7449e-03,  8.2131e-04, -1.8396e-02, -3.0917e-01],\n",
      "          [-3.6758e-02,  9.0228e-02,  1.7865e-01,  1.2992e-02, -1.7597e-01],\n",
      "          [ 1.1308e-01, -8.1991e-02,  5.4789e-02,  1.9350e-02, -2.1714e-01],\n",
      "          [ 1.7669e-02, -5.5163e-02, -2.9657e-02,  4.4243e-02, -5.0431e-02]],\n",
      "\n",
      "         [[ 2.7457e-01,  6.6500e-02,  3.0113e-01,  1.5521e-01,  1.8605e-03],\n",
      "          [ 1.4575e-01,  1.1282e-01,  4.2513e-01,  3.1606e-01, -3.0241e-02],\n",
      "          [ 5.6606e-02,  2.9230e-01,  3.2545e-01,  3.3254e-01,  4.3533e-02],\n",
      "          [ 1.9942e-01,  2.2977e-01,  2.3150e-01,  1.3125e-01,  9.8929e-02],\n",
      "          [ 3.2092e-01,  2.1969e-01,  7.6208e-02,  2.7242e-01,  1.5334e-01]],\n",
      "\n",
      "         [[ 6.7576e-03,  7.2211e-02,  1.8824e-02, -3.1849e-02, -1.4009e-01],\n",
      "          [-3.3081e-02,  1.9604e-02,  7.2066e-02,  1.6268e-01, -4.6875e-02],\n",
      "          [-1.3507e-01,  1.8197e-01,  1.1462e-01,  4.0994e-02, -4.4856e-02],\n",
      "          [ 1.0403e-01,  1.6053e-01,  7.0739e-02,  1.8009e-02, -4.5921e-02],\n",
      "          [-1.6251e-02, -6.2835e-02,  1.5791e-03,  9.3436e-02, -2.0560e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2830e-01,  1.6963e-01,  1.7952e-01,  1.4364e-01,  1.5052e-01],\n",
      "          [ 4.0921e-01,  3.7305e-01,  4.4687e-01,  4.9947e-01,  4.3410e-01],\n",
      "          [ 3.1668e-01,  2.1068e-01,  3.9070e-01,  2.9328e-01,  2.3531e-01],\n",
      "          [-1.5687e-02, -1.2507e-01, -2.4966e-01, -2.0559e-01, -1.9850e-01],\n",
      "          [-1.2438e-01, -3.8230e-01, -2.5803e-01, -2.3569e-01, -2.4584e-01]],\n",
      "\n",
      "         [[-1.6783e-01, -1.3674e-01,  3.3050e-02, -4.3632e-02, -2.4807e-04],\n",
      "          [ 1.3366e-02,  9.5274e-02,  1.3151e-01,  1.2205e-01,  2.0210e-01],\n",
      "          [ 2.4149e-02,  9.5964e-02,  1.4432e-01,  3.8984e-02, -6.1749e-03],\n",
      "          [-2.8528e-02, -2.4949e-01, -3.7937e-01, -3.3085e-01, -3.0097e-01],\n",
      "          [-1.9784e-01, -1.7176e-01, -1.7403e-01, -2.5421e-01, -1.4212e-01]],\n",
      "\n",
      "         [[-1.3489e-01, -1.5580e-01, -1.4530e-01, -1.3738e-01,  6.6478e-03],\n",
      "          [ 1.3236e-02,  2.1956e-01,  1.1001e-01,  2.0753e-01, -9.8584e-03],\n",
      "          [ 1.6980e-01,  2.2072e-01,  1.3845e-01,  3.4130e-02, -3.9858e-02],\n",
      "          [ 1.0681e-01, -1.0118e-02, -1.2911e-01, -1.1304e-01, -2.7895e-02],\n",
      "          [-3.0550e-02, -1.3658e-01, -1.6809e-01, -9.6747e-02,  5.5956e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8622e-01, -1.5910e-01,  7.3537e-02, -7.3880e-03,  9.9095e-03],\n",
      "          [-3.0051e-01, -2.6706e-01, -2.5038e-01, -1.0642e-01, -1.7236e-01],\n",
      "          [-4.2305e-01, -3.1818e-01, -2.8410e-01, -3.5134e-01, -2.6160e-01],\n",
      "          [-3.3912e-01, -3.6416e-01, -3.6198e-01, -3.1363e-01, -1.6725e-01],\n",
      "          [-1.0710e-01, -1.4329e-01,  1.0696e-01, -1.4145e-03,  6.4627e-02]],\n",
      "\n",
      "         [[ 2.5917e-01,  2.5054e-01,  1.9776e-01,  1.6858e-01,  2.3406e-01],\n",
      "          [ 2.1818e-01,  6.7733e-02,  1.4899e-01,  3.4637e-03,  1.3043e-01],\n",
      "          [-1.1128e-01, -4.8766e-03, -1.3183e-01, -4.3646e-02, -3.2674e-02],\n",
      "          [-1.6922e-01, -1.6126e-01, -1.6597e-01, -1.2530e-01, -1.5164e-01],\n",
      "          [ 1.5475e-01,  2.0618e-01,  1.9388e-01,  1.8414e-01,  3.0680e-02]],\n",
      "\n",
      "         [[ 2.8866e-01,  3.1219e-01,  2.7688e-01,  2.3172e-01,  1.7366e-01],\n",
      "          [ 1.6874e-01,  3.4461e-01,  2.2687e-01,  3.0903e-01,  1.3776e-01],\n",
      "          [ 1.9077e-01,  1.2975e-02,  1.9019e-02,  1.0318e-01,  3.7054e-02],\n",
      "          [ 2.0232e-01,  2.0239e-01,  2.7950e-02,  5.4113e-02, -9.0204e-03],\n",
      "          [ 3.4985e-01,  3.9195e-01,  2.6745e-01,  2.7742e-01,  1.5909e-01]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0139, -0.0044, -0.5735,  0.2704, -0.1364, -0.0615], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 2.4235e-02,  2.7999e-02, -2.1521e-02,  4.6564e-04,  2.6933e-02],\n",
      "          [ 7.4349e-02,  5.8407e-02, -3.1702e-02,  1.4303e-02, -4.5947e-02],\n",
      "          [-5.3336e-02,  6.7917e-02, -1.5819e-02, -4.1033e-02,  3.5342e-02],\n",
      "          [ 4.6558e-02,  2.2605e-02, -3.1175e-02, -6.0315e-02, -2.8564e-02],\n",
      "          [-3.8432e-02,  4.3933e-02, -3.6495e-02,  9.1546e-02, -6.6605e-02]],\n",
      "\n",
      "         [[ 2.0179e-02, -7.5060e-02,  7.5479e-02,  5.5767e-02,  5.1205e-02],\n",
      "          [ 3.4551e-02, -1.5204e-01, -1.5309e-01,  2.1911e-02,  1.9529e-02],\n",
      "          [-3.5189e-02, -4.7952e-02, -1.0125e-01, -2.0208e-01, -9.4152e-02],\n",
      "          [-3.2771e-02,  7.7151e-03, -8.4829e-02, -1.6926e-01, -7.9350e-02],\n",
      "          [-2.1216e-02,  1.1921e-01, -1.7108e-02, -1.3163e-01, -1.2223e-01]],\n",
      "\n",
      "         [[-1.2277e-01,  5.0048e-02,  2.6140e-01,  2.9528e-01, -9.6251e-02],\n",
      "          [-3.9031e-01, -2.4788e-01,  2.5565e-01,  3.5552e-01,  7.3905e-02],\n",
      "          [-3.2075e-01, -4.4499e-01,  3.7866e-02,  4.9524e-01,  1.4685e-01],\n",
      "          [-5.3357e-02, -3.4501e-01,  2.2863e-02,  2.1928e-01,  2.0511e-01],\n",
      "          [ 2.5152e-02, -1.3852e-01,  2.1209e-03,  9.6377e-02,  2.5261e-01]],\n",
      "\n",
      "         [[-2.0948e-01, -1.1322e-01,  3.9449e-02,  1.5392e-01,  3.1298e-02],\n",
      "          [-2.3345e-01, -2.9928e-01,  1.2549e-01,  3.2882e-01,  1.7367e-01],\n",
      "          [-1.3309e-01, -3.1113e-01, -2.6845e-02,  2.5828e-01,  1.5720e-01],\n",
      "          [-8.9836e-02, -3.7857e-01, -2.6485e-01,  8.0895e-02,  8.0897e-02],\n",
      "          [ 2.8929e-02, -1.9990e-01, -6.4995e-02,  2.0394e-02,  4.7576e-02]],\n",
      "\n",
      "         [[ 1.4759e-01,  2.1821e-01,  3.3946e-02, -5.8163e-02,  7.6334e-02],\n",
      "          [ 3.1082e-02,  1.0483e-01,  2.7186e-02, -2.5999e-02, -5.7164e-02],\n",
      "          [ 3.0195e-02,  9.1708e-04,  7.5876e-02,  5.5443e-02, -7.8389e-02],\n",
      "          [ 4.3309e-02, -6.5096e-02, -9.0326e-03,  1.5303e-01, -2.2830e-02],\n",
      "          [-4.6971e-02,  1.2434e-02,  3.3176e-02,  2.5113e-02, -3.3801e-02]],\n",
      "\n",
      "         [[-1.7585e-02, -1.1136e-01, -5.1028e-02, -8.7476e-02,  3.6836e-03],\n",
      "          [-1.4353e-01, -1.0277e-01, -7.5377e-02, -3.1728e-02,  4.4083e-02],\n",
      "          [-8.7303e-02, -1.3231e-01, -7.4987e-02,  6.0676e-02,  4.1969e-02],\n",
      "          [-5.2836e-02, -1.7410e-01, -8.7994e-02,  8.0016e-02,  9.5007e-02],\n",
      "          [ 9.1612e-04, -4.8668e-02,  8.4697e-03,  1.5852e-02,  9.3013e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2975e-02, -6.4288e-03, -4.2176e-02, -1.6554e-02, -3.5381e-02],\n",
      "          [ 1.4437e-02,  1.6360e-02, -7.4426e-02, -3.8391e-02,  3.2062e-02],\n",
      "          [ 7.8708e-03,  1.7429e-02, -6.5111e-02, -2.5208e-02,  5.4591e-03],\n",
      "          [ 2.6261e-02,  6.8604e-02, -6.4996e-03, -6.8258e-02,  1.0464e-03],\n",
      "          [ 4.2377e-02,  2.1285e-02, -5.4954e-04,  6.1557e-02,  1.6664e-02]],\n",
      "\n",
      "         [[-4.6569e-02, -2.7683e-02,  5.4391e-02, -4.6317e-02, -4.9967e-02],\n",
      "          [ 6.5155e-03, -1.1149e-01, -8.5767e-02,  1.4199e-02, -9.2788e-02],\n",
      "          [ 6.0885e-02, -6.1150e-02, -4.4038e-02, -1.2441e-01, -9.8918e-02],\n",
      "          [-7.0595e-02, -1.2494e-02, -9.7883e-02,  3.2543e-02, -1.0017e-01],\n",
      "          [-6.1319e-03, -5.6502e-02, -7.6990e-02, -6.2745e-02,  3.1928e-02]],\n",
      "\n",
      "         [[ 3.8719e-02,  1.2449e-01,  2.0909e-02, -2.8247e-03,  6.8944e-02],\n",
      "          [ 6.7414e-02,  6.7921e-02,  9.4979e-02, -4.2474e-02, -4.8754e-02],\n",
      "          [-9.7005e-02, -2.2398e-02,  3.8649e-02,  4.2048e-02,  3.4806e-02],\n",
      "          [ 5.6475e-03, -1.4340e-01, -8.4795e-02,  1.4990e-01,  2.2962e-01],\n",
      "          [-2.4360e-02, -2.0974e-01, -1.9683e-01,  9.2975e-02,  1.7065e-01]],\n",
      "\n",
      "         [[ 7.5779e-03, -1.4762e-02, -4.3882e-02, -8.8145e-02,  2.2983e-02],\n",
      "          [-5.7940e-02,  2.2634e-02,  5.5779e-02,  3.3065e-02, -7.0423e-03],\n",
      "          [-1.6177e-02, -9.6864e-02,  3.2833e-02,  5.5893e-03,  3.4003e-02],\n",
      "          [-5.6651e-02, -1.6715e-01, -5.2459e-02, -7.3670e-02,  3.9122e-02],\n",
      "          [-4.3190e-02, -5.5293e-02, -1.3294e-01, -2.5837e-02, -2.5109e-02]],\n",
      "\n",
      "         [[-6.1960e-03,  5.9344e-02, -1.1052e-01, -9.6487e-02, -1.4025e-01],\n",
      "          [-4.5824e-03,  2.1963e-02, -7.1329e-02, -1.7074e-01, -4.1380e-02],\n",
      "          [-7.3516e-02,  3.4900e-03,  5.6468e-02, -1.2488e-01, -1.6724e-01],\n",
      "          [-3.6029e-02, -6.1269e-02, -4.6297e-02, -1.2794e-01, -1.0017e-01],\n",
      "          [ 5.6452e-02, -3.4473e-02, -1.3587e-01, -5.2718e-02,  4.5830e-02]],\n",
      "\n",
      "         [[-4.9784e-02,  6.8565e-02,  1.1504e-02,  8.3926e-02,  1.2561e-02],\n",
      "          [-4.3940e-02,  6.6152e-02,  1.9609e-02,  1.2542e-01,  1.4072e-01],\n",
      "          [ 2.7089e-02,  6.7467e-02,  9.3623e-02,  1.3802e-01,  1.2572e-01],\n",
      "          [-9.0318e-02,  1.1790e-01,  7.3126e-02,  2.2994e-01,  2.1386e-01],\n",
      "          [-9.4550e-02, -7.6248e-02,  6.2416e-02,  2.3254e-01,  1.9276e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2475e-02, -1.2473e-02,  5.3952e-02,  5.7761e-02, -5.3486e-02],\n",
      "          [ 6.6586e-02,  6.5344e-02,  6.5125e-02, -2.5456e-02, -1.2936e-02],\n",
      "          [-1.8342e-02,  1.8145e-02, -8.3136e-02, -2.0602e-02,  1.5570e-03],\n",
      "          [ 4.7810e-02,  2.9700e-02, -4.9854e-02, -5.6937e-02,  6.6523e-02],\n",
      "          [ 6.4771e-02,  1.9629e-02,  4.6928e-02, -3.6409e-02, -6.8621e-02]],\n",
      "\n",
      "         [[ 8.3001e-02,  2.5353e-02,  2.0825e-02,  1.8926e-02,  2.2654e-02],\n",
      "          [ 7.0411e-02,  1.2437e-02,  3.2195e-02,  7.4817e-02, -6.3253e-03],\n",
      "          [ 9.3851e-02,  6.9394e-02,  9.7136e-02,  2.8361e-02, -4.9653e-03],\n",
      "          [ 7.7720e-02,  9.3556e-02,  3.7375e-02,  3.6493e-02, -3.7952e-02],\n",
      "          [-1.9470e-03, -8.5263e-02,  7.1029e-02, -9.6570e-03, -3.5161e-02]],\n",
      "\n",
      "         [[ 8.0330e-02,  4.5480e-02,  5.7252e-02,  8.3203e-02, -6.4931e-02],\n",
      "          [ 5.0113e-03, -1.6785e-02,  3.1239e-02, -4.0733e-02,  5.6466e-02],\n",
      "          [ 3.8705e-02, -7.9556e-02, -6.5142e-03, -6.3724e-02,  7.3686e-02],\n",
      "          [-8.6110e-02,  1.8497e-02, -5.4704e-02,  2.2454e-02,  3.6594e-02],\n",
      "          [-8.1063e-02, -7.8905e-02,  9.8827e-03,  7.1401e-02, -2.9768e-02]],\n",
      "\n",
      "         [[ 8.3208e-02,  5.7798e-02, -2.5200e-02, -2.3619e-02, -1.9472e-02],\n",
      "          [-2.6841e-02, -6.4900e-02, -5.6962e-03, -2.4517e-02,  5.4791e-02],\n",
      "          [-4.8485e-02, -5.5205e-02, -2.2738e-02,  2.7300e-02, -7.8542e-02],\n",
      "          [-1.0479e-01, -7.9955e-02, -2.2348e-02, -1.7513e-02,  1.1991e-02],\n",
      "          [-1.7205e-02, -6.1287e-02,  3.1668e-02, -7.0208e-02, -6.3496e-02]],\n",
      "\n",
      "         [[ 7.4467e-02, -4.0832e-02, -1.1894e-03,  5.5417e-02,  3.5349e-02],\n",
      "          [ 3.2319e-03, -4.6934e-02,  3.3376e-02, -1.4420e-02,  3.7939e-03],\n",
      "          [ 6.1928e-03, -3.5556e-04,  1.6363e-02, -5.6239e-02, -2.8536e-02],\n",
      "          [ 7.5204e-02,  9.8877e-02,  8.9274e-02,  7.6293e-02,  1.0370e-01],\n",
      "          [ 1.0855e-01, -1.4279e-02,  4.8826e-02,  8.2953e-02,  7.7199e-02]],\n",
      "\n",
      "         [[ 7.0451e-02, -6.8601e-03,  8.3863e-02,  4.3960e-02,  4.8907e-02],\n",
      "          [-5.8383e-02, -1.5122e-02, -4.8614e-02, -6.9348e-03, -4.6834e-02],\n",
      "          [-4.9234e-02, -8.7293e-02, -6.7634e-02, -8.8041e-02, -5.9906e-03],\n",
      "          [-1.0562e-01, -2.4409e-03, -1.9168e-02, -6.9028e-03, -8.0086e-02],\n",
      "          [-6.8404e-02, -7.1558e-02, -1.0087e-01, -2.6981e-02, -1.4964e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1755e-01,  1.2949e-01,  8.5856e-03,  3.1736e-02,  8.1212e-02],\n",
      "          [ 4.6016e-02,  1.3377e-02,  4.7050e-02,  2.3782e-02,  8.1982e-02],\n",
      "          [ 7.5137e-02,  8.4261e-02,  5.5788e-02,  1.5524e-01,  2.0165e-02],\n",
      "          [ 2.4633e-02,  6.8695e-02,  8.5751e-02,  7.8867e-02,  1.0054e-01],\n",
      "          [ 1.1688e-03,  7.3161e-02,  1.0480e-01,  2.4940e-02,  4.3178e-02]],\n",
      "\n",
      "         [[ 1.4065e-01,  7.2169e-02,  1.7929e-02, -3.1380e-02,  2.7031e-02],\n",
      "          [ 2.1207e-01,  2.2663e-01,  1.2143e-01,  9.7265e-02, -2.2497e-02],\n",
      "          [ 2.0333e-01,  2.2807e-01,  2.1862e-01,  7.8588e-02,  1.5995e-01],\n",
      "          [ 4.7652e-02,  1.0470e-01,  1.3666e-01,  1.1602e-02,  1.3010e-01],\n",
      "          [ 7.1453e-02,  6.4245e-02,  3.5115e-02,  4.2948e-02,  7.2999e-02]],\n",
      "\n",
      "         [[-5.0994e-02, -1.4842e-01, -1.3493e-01, -1.6256e-01,  1.5753e-02],\n",
      "          [-2.4590e-02, -1.9420e-01, -1.5488e-01, -2.7638e-01, -2.4789e-01],\n",
      "          [ 1.3161e-01,  9.3965e-02,  9.1091e-03, -8.9858e-02, -2.4336e-01],\n",
      "          [ 1.7927e-01,  4.4144e-02,  1.9245e-01,  1.3007e-01,  4.5600e-02],\n",
      "          [ 1.6303e-01,  9.9442e-02,  1.4907e-01,  2.4479e-01,  1.2680e-01]],\n",
      "\n",
      "         [[-1.6710e-02, -2.5188e-01, -2.2562e-01, -1.5368e-01, -1.0744e-01],\n",
      "          [ 1.0332e-02, -1.4518e-01, -1.4400e-01, -2.1962e-01, -1.3069e-01],\n",
      "          [ 1.6550e-01,  1.2932e-01, -2.4766e-02, -1.1378e-01, -1.0135e-01],\n",
      "          [ 1.3385e-01,  8.2333e-02,  1.9715e-01,  4.5170e-02, -7.5116e-02],\n",
      "          [ 1.0390e-01,  1.1436e-01,  2.0946e-01,  1.8934e-01,  1.8002e-01]],\n",
      "\n",
      "         [[ 6.0098e-02,  3.8625e-02,  7.7113e-02,  3.9208e-02,  6.3866e-02],\n",
      "          [ 2.4815e-02,  6.0395e-03,  7.4169e-02,  4.6039e-02,  2.6822e-02],\n",
      "          [-3.4599e-02, -1.7864e-02,  1.8784e-03, -6.7289e-02,  4.4354e-02],\n",
      "          [ 5.6140e-02, -5.8632e-02, -1.2784e-02, -3.1042e-02, -4.0934e-02],\n",
      "          [-5.7351e-02, -1.5614e-02, -3.7605e-02, -6.3021e-02, -3.7498e-02]],\n",
      "\n",
      "         [[ 4.5715e-02, -2.1719e-02, -6.7101e-04,  1.3166e-01, -3.9060e-04],\n",
      "          [ 5.6333e-03,  9.5846e-02,  1.8852e-02,  4.2419e-02, -4.0901e-02],\n",
      "          [ 7.2085e-02,  1.2877e-02, -2.3344e-02, -2.7904e-02, -3.9013e-02],\n",
      "          [ 2.3067e-02,  4.0230e-02, -7.8157e-03, -2.3253e-02, -7.5376e-02],\n",
      "          [-9.7303e-02,  2.6694e-02, -2.1853e-02, -4.3168e-02,  3.4309e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0858e-02,  4.9948e-02,  4.0141e-02, -1.1071e-02,  1.0841e-01],\n",
      "          [ 7.4836e-02, -6.8755e-03,  8.1171e-02,  1.1531e-02,  7.4455e-02],\n",
      "          [ 1.0571e-01,  8.9649e-02, -2.7825e-02,  1.1344e-02,  1.5403e-03],\n",
      "          [ 6.1340e-02,  4.0206e-02,  1.2074e-01, -1.3394e-02,  2.8979e-02],\n",
      "          [-2.3007e-02,  5.9687e-03,  1.0780e-01, -2.2832e-02, -3.7691e-02]],\n",
      "\n",
      "         [[-7.0348e-02, -4.9389e-02,  1.0493e-01, -7.5814e-02, -6.3704e-02],\n",
      "          [ 8.9444e-02,  1.1178e-01,  9.0371e-02,  8.9350e-03, -1.1585e-02],\n",
      "          [-5.3501e-04,  1.4348e-01,  1.1706e-01,  8.0345e-02, -3.0834e-02],\n",
      "          [ 4.0424e-02,  1.4205e-01,  5.4045e-02,  5.2023e-02, -1.0743e-02],\n",
      "          [ 1.2163e-01,  1.6708e-01,  2.0779e-01,  8.6040e-02,  1.1551e-01]],\n",
      "\n",
      "         [[-1.9057e-01, -9.7911e-02,  1.3097e-01,  8.1174e-02, -3.0289e-02],\n",
      "          [-2.3796e-01, -1.5892e-01,  6.8115e-02,  8.9486e-02, -1.3257e-01],\n",
      "          [-8.6039e-02, -1.7812e-01,  1.9329e-01,  1.5305e-01, -8.5535e-02],\n",
      "          [-1.9469e-01, -6.0325e-02,  6.5167e-02,  9.4078e-02, -1.1493e-01],\n",
      "          [-1.2983e-01, -1.5279e-01, -3.8545e-02, -1.0398e-01,  1.9135e-02]],\n",
      "\n",
      "         [[ 2.1186e-01,  5.7140e-02,  2.0831e-01,  1.9630e-01, -2.6953e-03],\n",
      "          [ 2.1989e-01, -4.0169e-02,  2.7656e-01,  2.8373e-01,  1.4163e-02],\n",
      "          [ 1.4943e-01,  8.8602e-02,  2.3818e-01,  1.7730e-01, -4.9679e-03],\n",
      "          [ 1.0940e-01,  8.6431e-02,  1.8700e-01,  5.0110e-02,  5.3069e-02],\n",
      "          [ 6.5705e-02,  1.7119e-01, -1.2496e-02,  1.3048e-01,  7.7658e-02]],\n",
      "\n",
      "         [[ 4.7786e-03,  4.9340e-03, -5.7255e-02,  1.9769e-02,  2.4297e-03],\n",
      "          [-9.1227e-02,  2.1867e-02, -9.5898e-03, -2.9774e-02, -4.1251e-02],\n",
      "          [-6.2419e-02, -5.9563e-02, -3.9454e-03,  6.1641e-02, -1.1095e-01],\n",
      "          [-1.4485e-01, -7.8079e-02, -2.1143e-02, -6.7734e-02, -6.1967e-03],\n",
      "          [-6.8688e-02,  7.0951e-02,  3.1598e-02, -1.2441e-02, -8.9511e-02]],\n",
      "\n",
      "         [[-1.2495e-01, -1.8362e-01, -8.4670e-02, -4.1018e-02, -5.4652e-02],\n",
      "          [-2.2851e-01, -5.4532e-02, -1.1516e-01,  4.6829e-02,  1.1278e-02],\n",
      "          [-2.1397e-01, -1.4911e-01,  1.9990e-02,  3.8825e-02, -5.7193e-02],\n",
      "          [-2.2841e-01, -1.8960e-01, -9.1950e-02,  9.3232e-04, -1.4549e-01],\n",
      "          [-3.8528e-01, -2.0736e-01, -1.7464e-01, -7.6713e-02, -1.6060e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9180e-02,  4.3256e-02, -4.3283e-02,  4.7444e-02, -6.6798e-04],\n",
      "          [-7.9581e-02, -6.3889e-02, -6.7650e-02,  7.3286e-02, -6.4010e-02],\n",
      "          [ 1.9738e-02,  5.6148e-02,  4.4448e-02, -3.6600e-02, -3.7399e-02],\n",
      "          [-1.6276e-02,  4.2353e-02, -6.3156e-02, -5.2220e-02, -2.6649e-02],\n",
      "          [ 2.7563e-02,  5.6649e-02, -8.7005e-03, -2.3197e-02, -2.6923e-02]],\n",
      "\n",
      "         [[ 7.9243e-02, -1.8846e-02,  6.2473e-02,  2.4484e-03,  7.5246e-02],\n",
      "          [-4.8266e-02, -6.9122e-02, -6.8340e-02, -2.3556e-02, -3.8510e-02],\n",
      "          [ 2.1958e-02, -5.3440e-02,  1.1137e-02,  4.3831e-02,  5.2150e-02],\n",
      "          [ 1.0449e-02, -6.3930e-02,  1.5840e-02,  3.3644e-03,  4.7717e-02],\n",
      "          [-1.8867e-02, -6.2235e-02,  3.0254e-02, -3.4129e-03, -5.8332e-02]],\n",
      "\n",
      "         [[ 5.9004e-02, -1.0134e-02,  3.0940e-02,  6.9914e-02, -6.2154e-02],\n",
      "          [ 4.4954e-02, -1.8517e-02,  5.5955e-02, -2.9465e-02, -6.5772e-02],\n",
      "          [-5.4587e-02,  7.5510e-03, -1.5821e-02,  1.0838e-02,  4.8434e-02],\n",
      "          [ 2.8070e-02, -3.6214e-02,  5.3420e-02, -4.1678e-02, -7.8299e-02],\n",
      "          [-3.9898e-02,  9.1976e-03, -2.4712e-02,  5.5687e-04,  1.9428e-02]],\n",
      "\n",
      "         [[-3.8923e-02, -2.2727e-02, -6.3548e-02,  5.3202e-02,  6.6954e-02],\n",
      "          [ 2.5039e-02, -4.6104e-02, -7.3035e-02, -8.3590e-02,  6.0105e-02],\n",
      "          [-1.5100e-02, -2.0480e-02,  4.7204e-02, -5.8386e-02, -2.2510e-02],\n",
      "          [-3.9409e-02, -8.0975e-03, -5.7022e-02,  5.4262e-02, -2.0009e-02],\n",
      "          [-3.3975e-03,  4.3389e-02, -3.0235e-02, -5.9651e-02, -5.0775e-03]],\n",
      "\n",
      "         [[-1.5883e-02, -2.7413e-02, -4.8551e-02,  6.4266e-02, -6.5793e-02],\n",
      "          [-1.0648e-02,  6.0167e-02,  5.5489e-03,  3.2647e-02, -7.8285e-02],\n",
      "          [-1.3138e-02, -3.8315e-02,  1.6040e-02,  4.1388e-02, -3.6757e-02],\n",
      "          [-1.9488e-02,  3.1963e-02, -2.6397e-02, -4.4915e-02, -6.3826e-02],\n",
      "          [ 5.3255e-02,  5.5554e-02,  2.5079e-02,  8.1216e-02, -7.9079e-02]],\n",
      "\n",
      "         [[-2.6770e-02,  7.5872e-02,  8.0276e-02, -7.7945e-02,  4.0152e-02],\n",
      "          [ 2.5191e-02,  3.4457e-02, -8.1194e-02, -7.6677e-02, -1.6313e-02],\n",
      "          [ 1.5485e-02, -2.1302e-02, -1.3015e-02, -6.0947e-02, -2.2799e-03],\n",
      "          [ 1.3968e-02,  1.4432e-02, -6.8108e-02, -2.8294e-03,  5.7532e-02],\n",
      "          [-4.1042e-02,  1.6443e-02,  4.2301e-02,  5.4395e-02,  5.0287e-02]]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1602,  0.0270, -0.0316, -0.3111, -0.0456,  0.0718,  0.1121, -0.0391,\n",
      "        -0.2732, -0.0304, -0.1125, -0.0454, -0.0550, -0.0544,  0.3728, -0.0696],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0210, -0.0511, -0.0698,  ..., -0.0413, -0.0350, -0.0142],\n",
      "        [ 0.0866, -0.0059, -0.0082,  ..., -0.0033, -0.0228, -0.0357],\n",
      "        [-0.0418,  0.0405, -0.0016,  ...,  0.0377,  0.0095,  0.0163],\n",
      "        ...,\n",
      "        [-0.0687, -0.0146, -0.0233,  ...,  0.0224,  0.0191, -0.0078],\n",
      "        [-0.0067,  0.0060, -0.0044,  ...,  0.0458, -0.0344, -0.0095],\n",
      "        [-0.0404, -0.0294,  0.0201,  ...,  0.0463, -0.0392,  0.0205]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 9.0313e-02,  2.1553e-02,  7.2623e-03, -2.1046e-02,  1.5889e-02,\n",
      "        -1.5404e-02,  6.0606e-02, -4.1316e-03, -4.6272e-02,  4.0753e-02,\n",
      "         2.0354e-02,  1.3763e-02, -4.5426e-02,  2.7818e-02,  3.8302e-03,\n",
      "        -5.6616e-02,  4.7824e-03, -9.6087e-02, -1.6081e-03, -6.9901e-02,\n",
      "        -6.6977e-04, -1.1680e-02, -2.3323e-02,  7.3004e-02,  1.8305e-02,\n",
      "        -4.2188e-02, -9.8654e-03,  2.4499e-03, -1.9851e-02,  5.5694e-02,\n",
      "         1.6004e-02,  3.1884e-02,  7.0254e-03,  4.0651e-02,  8.1594e-02,\n",
      "         4.8224e-02,  1.5095e-02,  6.2761e-02, -7.7831e-02,  4.7910e-02,\n",
      "        -4.4688e-02, -4.9957e-02, -4.5271e-02,  9.9929e-03, -4.1893e-02,\n",
      "        -8.5345e-02, -3.7782e-02,  5.3778e-02,  9.3185e-03, -2.8873e-02,\n",
      "        -8.1971e-02,  2.2543e-03, -1.0033e-02, -3.3445e-02, -5.3931e-03,\n",
      "         2.3296e-02, -4.6631e-02, -1.7998e-02, -5.7177e-02, -1.4429e-01,\n",
      "        -1.2352e-02,  7.5958e-02,  3.0987e-03,  3.1019e-02,  2.8890e-02,\n",
      "        -1.6498e-02,  9.1636e-02, -5.0312e-03,  1.0422e-02, -1.3869e-02,\n",
      "         9.0858e-02,  3.5673e-02, -6.0289e-03,  6.4048e-02,  4.1455e-03,\n",
      "        -9.1039e-02,  9.7284e-03,  3.7978e-02,  3.2591e-02, -2.2295e-02,\n",
      "         5.8796e-02, -3.4676e-02,  1.0067e-01, -1.2217e-02,  1.3564e-04,\n",
      "         2.5286e-02,  6.9895e-02, -6.2808e-02, -1.7594e-02,  2.6924e-02,\n",
      "         4.8451e-02, -3.7563e-02, -6.5255e-02,  2.3834e-02, -7.5801e-02,\n",
      "         1.4565e-04, -4.5295e-02,  2.1140e-02,  2.6140e-02, -4.3434e-02,\n",
      "        -1.0451e-01, -1.8579e-02, -3.0471e-02,  3.9745e-02, -4.1660e-02,\n",
      "        -4.2780e-02,  1.2791e-01, -1.9997e-02, -2.5622e-02,  5.4002e-03,\n",
      "         2.1120e-02,  4.9116e-02,  7.7376e-02,  1.5548e-02,  2.9176e-02,\n",
      "        -1.9434e-03, -9.7200e-02,  5.6909e-02, -3.5370e-02, -4.2862e-02],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0436,  0.0751, -0.0519,  ...,  0.0581,  0.0119,  0.0130],\n",
      "        [ 0.0611, -0.0479,  0.0386,  ...,  0.1018, -0.0932,  0.0050],\n",
      "        [-0.1126,  0.0224, -0.0342,  ..., -0.1190, -0.0638, -0.0554],\n",
      "        ...,\n",
      "        [-0.0740,  0.0275, -0.0272,  ...,  0.0561, -0.0570, -0.0282],\n",
      "        [-0.0478,  0.0315, -0.0216,  ...,  0.0745, -0.0010, -0.0590],\n",
      "        [ 0.0457,  0.0801,  0.0006,  ...,  0.1131,  0.0621, -0.0114]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0715,  0.0215,  0.0532, -0.0931, -0.0015, -0.0253, -0.0210, -0.0274,\n",
      "        -0.0934, -0.0165, -0.0912, -0.0224, -0.0510, -0.0103,  0.1216,  0.1540,\n",
      "        -0.0228, -0.0806,  0.2326, -0.0732,  0.0197, -0.0849,  0.1355, -0.0950,\n",
      "        -0.0677,  0.1389,  0.0015,  0.0103, -0.0588,  0.0842, -0.0209,  0.0535,\n",
      "         0.0604,  0.1664,  0.1168,  0.0220, -0.0042,  0.0817, -0.0100,  0.0135,\n",
      "        -0.0043, -0.0799, -0.0672,  0.0464, -0.0084,  0.0662,  0.0865,  0.0098,\n",
      "         0.0068,  0.2010, -0.0086,  0.0167, -0.0632,  0.0480, -0.0104,  0.0017,\n",
      "         0.0057, -0.0695, -0.1702,  0.1255,  0.0054, -0.0767,  0.2041,  0.0596,\n",
      "        -0.0429,  0.0218, -0.0854,  0.0759, -0.0830, -0.0788,  0.1060,  0.0382,\n",
      "        -0.0047, -0.0897,  0.0683,  0.0472,  0.1425,  0.0361,  0.1287,  0.0432,\n",
      "        -0.1593,  0.0792,  0.0884,  0.1603], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.0848e-01,  5.4673e-02, -2.0476e-01, -1.7095e-01,  4.4379e-03,\n",
      "          2.4106e-02, -9.3252e-02,  1.0475e-01, -1.3484e-02,  6.5087e-02,\n",
      "          1.0154e-01,  1.5419e-01,  1.3168e-01, -9.6186e-02, -4.0797e-02,\n",
      "         -1.0489e-02,  1.1888e-01,  5.1264e-02, -1.5851e-01, -2.2554e-01,\n",
      "          1.2923e-01,  6.9263e-02,  1.5611e-01,  1.0852e-01,  1.3445e-01,\n",
      "         -1.1558e-01, -1.3289e-01, -1.3676e-02,  2.3863e-02,  1.0880e-01,\n",
      "         -2.6929e-02,  7.9853e-02, -7.6985e-02, -6.2916e-02, -9.1668e-03,\n",
      "          8.6837e-03,  3.5492e-01, -1.2459e-01, -1.1789e-01, -2.0031e-01,\n",
      "         -8.6348e-02,  2.2285e-01,  3.7898e-02,  9.6812e-02, -1.9417e-01,\n",
      "          8.6045e-02, -7.8646e-03,  1.5549e-01, -1.2792e-01, -3.7176e-02,\n",
      "          1.1320e-01,  1.1211e-01,  2.5714e-01,  1.1896e-01,  3.4615e-02,\n",
      "          1.6081e-02,  9.4808e-02,  3.0889e-02,  3.3701e-01,  5.9569e-02,\n",
      "         -6.4931e-02,  9.9352e-02, -1.3293e-01, -8.6768e-02,  1.5315e-02,\n",
      "          4.3022e-01,  3.2566e-01, -2.9418e-01,  1.3403e-01,  3.7013e-02,\n",
      "         -1.5865e-01,  3.0640e-01, -1.3609e-01,  6.5948e-02,  1.0170e-02,\n",
      "          6.8644e-02, -1.7529e-01, -1.2612e-01, -1.1602e-01,  2.3319e-02,\n",
      "          1.2598e-01,  1.5129e-01, -5.6222e-02,  1.1852e-02],\n",
      "        [ 7.8166e-02,  4.5514e-02, -1.9497e-01,  1.1478e-01,  4.1080e-02,\n",
      "         -5.3069e-02, -3.7388e-02, -6.4874e-02,  9.8793e-02,  5.2212e-02,\n",
      "          1.7526e-02, -1.7658e-01,  2.0811e-02, -4.4343e-02, -2.1926e-01,\n",
      "          1.8639e-01, -1.0447e-01,  4.8112e-02,  1.6900e-01,  2.3830e-01,\n",
      "         -2.1394e-01, -7.9315e-02,  1.1396e-01,  3.3728e-02, -1.3274e-01,\n",
      "          2.7487e-01,  9.1925e-02, -3.0325e-02, -1.4665e-01,  3.1382e-02,\n",
      "         -2.4899e-01,  1.2607e-02, -1.1918e-03, -1.3739e-01,  4.6564e-01,\n",
      "         -1.7004e-01, -1.5409e-01,  8.0677e-02,  2.7475e-01,  4.7116e-02,\n",
      "          3.8691e-02, -3.6522e-01, -8.2927e-02, -5.9452e-02,  1.3024e-01,\n",
      "          1.3077e-01, -6.0309e-03,  1.3469e-01,  1.2064e-01, -4.2351e-02,\n",
      "          1.0961e-01,  2.8420e-01,  4.8265e-02,  1.6288e-01,  6.7588e-02,\n",
      "         -1.0713e-01,  1.7282e-01, -7.4615e-02, -1.6985e-01, -8.9406e-02,\n",
      "         -1.1987e-01,  6.3876e-02, -1.2769e-01,  1.9006e-01,  4.3308e-02,\n",
      "         -2.2349e-01,  1.9239e-02, -1.0593e-01, -1.0541e-01,  1.6140e-01,\n",
      "          7.4498e-02,  2.5604e-01, -7.4018e-02, -7.9875e-02,  2.0246e-02,\n",
      "         -1.0552e-01, -8.9247e-04,  1.0224e-01, -2.4970e-01,  9.4795e-02,\n",
      "         -1.7347e-01, -8.7922e-02, -1.9990e-01, -2.7912e-01],\n",
      "        [ 9.7251e-02,  1.3644e-01,  2.0163e-01, -1.8849e-01, -2.7505e-02,\n",
      "          1.1856e-01, -1.0701e-02,  1.5632e-02, -1.8329e-01, -1.1869e-02,\n",
      "          1.5478e-01,  2.1329e-01,  1.6145e-01,  9.7584e-02, -6.2698e-02,\n",
      "         -2.0636e-01,  1.9662e-01, -9.7507e-02,  7.2032e-02,  1.2539e-01,\n",
      "          2.2000e-01, -1.1696e-01,  8.1075e-02, -1.9279e-01,  3.1913e-01,\n",
      "          2.6761e-02, -3.5228e-02,  4.5911e-02,  3.9631e-02, -6.1608e-03,\n",
      "          8.2859e-02, -2.2675e-02, -2.6327e-02,  1.5589e-01,  1.7704e-01,\n",
      "         -4.2309e-02, -2.7042e-02,  6.9841e-02, -1.2048e-01,  2.0423e-01,\n",
      "         -1.5684e-01, -7.3842e-03, -1.3721e-01, -1.2529e-01, -1.0892e-01,\n",
      "         -1.2853e-01,  2.2451e-02,  1.5437e-01, -2.0969e-01,  1.7555e-02,\n",
      "         -8.4039e-02, -5.2032e-02, -5.4587e-02,  1.8686e-01,  1.3155e-02,\n",
      "         -1.0698e-02,  2.2156e-01,  8.3437e-02, -8.3400e-02, -1.0923e-03,\n",
      "         -1.4504e-01, -3.7488e-02,  2.1801e-01,  8.6723e-02, -1.5683e-01,\n",
      "          2.2990e-01,  2.7722e-01,  1.5751e-02,  7.5779e-02, -6.2639e-02,\n",
      "          1.8474e-02, -1.0026e-01, -2.2143e-02,  2.9509e-02, -1.5081e-01,\n",
      "         -8.3550e-02, -1.3896e-01,  2.1057e-01,  9.6870e-02, -2.1473e-01,\n",
      "         -1.6406e-01,  5.7339e-02,  2.2563e-01,  1.1386e-01],\n",
      "        [-6.3047e-02,  1.6654e-01,  1.6693e-01,  1.5590e-02,  8.0694e-02,\n",
      "         -6.6861e-02,  1.0340e-01,  3.4973e-02, -5.3692e-02,  1.0437e-01,\n",
      "          1.6295e-01, -6.1067e-02,  7.3962e-03,  3.2425e-01, -4.0577e-03,\n",
      "         -9.0166e-02, -1.4582e-01,  1.4994e-01, -5.3403e-02, -4.8703e-02,\n",
      "          1.9563e-01,  3.8839e-02,  7.8860e-03, -6.4398e-02, -2.0226e-01,\n",
      "         -1.5931e-01, -7.4400e-02, -5.0032e-02, -3.1092e-03, -2.0020e-01,\n",
      "          1.3574e-01, -8.3169e-02,  7.8928e-02,  8.8497e-02, -1.8354e-01,\n",
      "          4.4466e-02,  6.1954e-02,  1.8656e-01, -8.7612e-02,  3.6913e-02,\n",
      "          2.0539e-01,  4.2610e-02,  7.4991e-02,  4.5656e-02,  9.0293e-02,\n",
      "         -7.6848e-02,  3.0208e-02,  1.4444e-01, -1.8025e-02,  1.3676e-01,\n",
      "         -5.8092e-02, -2.2102e-02, -9.4965e-03,  3.7432e-02, -1.0733e-01,\n",
      "         -8.4004e-02,  2.2582e-02, -1.4996e-01, -3.7657e-02,  8.6784e-03,\n",
      "          1.3886e-01, -7.3709e-02,  5.9410e-02, -7.1220e-02, -2.7057e-02,\n",
      "         -3.6231e-02, -4.6913e-02, -8.8300e-02, -9.2154e-02,  1.1907e-01,\n",
      "          6.6235e-02, -2.1679e-01,  3.6903e-02,  6.1888e-02,  2.8742e-02,\n",
      "          1.0504e-01,  1.7270e-01, -9.1174e-02,  1.7144e-01,  4.2558e-02,\n",
      "          2.4684e-02,  1.4831e-02, -9.4746e-02, -4.8257e-02],\n",
      "        [-8.4472e-06,  9.6659e-02, -9.2002e-02,  7.0294e-02, -8.3529e-02,\n",
      "         -9.8067e-02, -4.5489e-02,  9.2418e-02, -1.8129e-01, -9.2866e-02,\n",
      "         -2.1557e-01,  7.6129e-02, -1.1889e-01, -8.5754e-03,  4.4373e-02,\n",
      "          1.7956e-01, -1.0180e-01, -2.2176e-02,  2.2426e-01, -3.4697e-03,\n",
      "          9.2871e-02, -1.1976e-01,  2.3949e-01, -2.9261e-02, -1.3141e-01,\n",
      "          1.6381e-02, -2.0237e-01,  2.2462e-01,  7.0793e-02,  2.3114e-01,\n",
      "         -5.0154e-02,  2.0457e-02, -2.3339e-01,  1.6018e-01, -1.0543e-01,\n",
      "         -5.4245e-02,  1.1714e-01, -3.5285e-01,  1.2521e-01, -4.6973e-02,\n",
      "         -1.8954e-01, -1.0881e-01, -9.5556e-02, -1.1139e-01,  1.3659e-01,\n",
      "         -1.8785e-01, -8.9274e-02, -1.1523e-01, -1.4828e-01,  3.8962e-02,\n",
      "          7.7427e-02, -2.7923e-01,  1.0997e-01, -1.4083e-01, -1.0559e-01,\n",
      "         -1.3471e-01,  7.6759e-02, -1.1159e-01, -7.7060e-02,  1.6690e-01,\n",
      "          2.1152e-01,  6.8001e-02,  1.1341e-01, -1.0033e-01,  9.2568e-02,\n",
      "          8.4154e-02, -1.6377e-01,  1.7748e-01, -3.6140e-02,  1.0992e-01,\n",
      "         -1.5045e-01, -2.0674e-02,  9.0502e-02, -1.0811e-02,  1.0215e-01,\n",
      "         -1.2002e-02,  2.1192e-01, -1.5044e-01, -4.7141e-03,  6.3696e-02,\n",
      "         -7.2514e-02, -1.0609e-01,  2.5225e-01,  2.0985e-01],\n",
      "        [ 1.3130e-01, -1.5661e-01,  2.1395e-01,  1.9122e-01, -6.3518e-02,\n",
      "          8.7837e-02, -8.4541e-02, -1.4422e-01, -4.0468e-02, -4.5854e-02,\n",
      "          1.4673e-01, -2.2710e-02,  5.9887e-02,  7.3151e-02,  3.5394e-02,\n",
      "         -2.1387e-01, -3.8587e-02,  1.3937e-01, -2.1570e-01,  2.3581e-02,\n",
      "          3.9877e-02, -6.9095e-02,  3.3418e-02,  1.7110e-01,  1.9237e-02,\n",
      "         -4.4481e-02,  6.0744e-02,  3.1748e-02, -1.1067e-01, -3.0581e-01,\n",
      "          1.0730e-01,  3.1278e-02,  1.4652e-01, -1.4636e-01, -2.0199e-01,\n",
      "          2.0984e-02, -1.5180e-02,  7.0678e-02, -1.4351e-01,  4.5603e-02,\n",
      "         -2.0225e-03,  4.6340e-02, -5.2004e-02, -4.1764e-02,  1.5650e-01,\n",
      "         -1.3943e-01,  8.2364e-02, -1.0656e-01, -1.5242e-01,  1.9805e-02,\n",
      "          3.3964e-02, -1.0827e-01, -1.6669e-01, -2.3710e-01,  6.6935e-02,\n",
      "          2.5261e-01, -2.2058e-01,  4.1585e-02,  3.7975e-02, -4.0799e-02,\n",
      "          9.1061e-02,  2.1483e-02, -1.1484e-01, -4.4571e-02, -6.7725e-02,\n",
      "         -7.8991e-02,  1.7673e-01,  1.3867e-01, -9.2405e-03, -6.5236e-02,\n",
      "         -6.3457e-02, -9.2945e-02, -1.1964e-01,  3.0458e-02,  7.8781e-02,\n",
      "         -2.6501e-02,  2.6146e-01,  5.0953e-02,  2.0012e-01,  5.8144e-02,\n",
      "          1.0315e-01, -7.4587e-02, -5.4592e-02,  5.8138e-02],\n",
      "        [ 1.0138e-01, -1.9034e-01, -1.3499e-01, -2.0051e-01,  1.3246e-01,\n",
      "          1.6288e-01,  6.2045e-02, -3.1526e-01, -1.0231e-01, -4.6695e-02,\n",
      "         -1.4106e-01, -1.1044e-01, -4.4813e-02, -4.1372e-02,  3.4418e-01,\n",
      "          1.1953e-01,  6.4364e-02,  8.9878e-02,  1.1387e-01, -1.1247e-01,\n",
      "         -7.8729e-02,  2.4187e-02,  4.5810e-02, -1.8786e-01, -9.5111e-02,\n",
      "          1.0982e-01,  5.7668e-02, -3.9532e-01, -5.3675e-02, -2.1286e-01,\n",
      "          1.6816e-01, -1.1655e-03, -1.0671e-01,  3.6072e-02, -1.5748e-01,\n",
      "          1.3549e-01, -1.9217e-01,  1.5155e-01, -2.1415e-01, -1.5902e-01,\n",
      "          5.3861e-02,  3.4919e-02, -1.7629e-01,  7.2849e-02, -2.8401e-01,\n",
      "          8.6384e-02,  1.6903e-01,  1.6942e-01,  1.3876e-01,  3.9560e-01,\n",
      "          1.0664e-02,  1.5107e-01,  1.4041e-01, -3.5485e-02, -3.9684e-02,\n",
      "          1.2216e-01,  1.0021e-01,  3.2820e-02, -2.5340e-01,  3.1884e-01,\n",
      "         -9.1262e-02,  1.0929e-01,  2.2611e-01, -2.2844e-01, -2.1868e-01,\n",
      "         -4.5777e-02, -1.2247e-01,  1.3533e-01,  2.6086e-02, -6.0956e-02,\n",
      "          2.0565e-01, -4.6509e-03, -7.8913e-02, -5.9165e-02, -1.9627e-02,\n",
      "          9.5751e-02, -5.2024e-02,  5.3032e-02, -3.0803e-02,  9.8918e-02,\n",
      "         -1.9591e-01,  1.1183e-01, -1.3390e-01,  9.2264e-02],\n",
      "        [-3.0808e-02, -1.0321e-01, -4.7925e-02,  5.7997e-02,  1.2575e-01,\n",
      "          1.1543e-01,  5.2809e-02, -3.3787e-02,  1.8309e-01,  1.5931e-03,\n",
      "          1.5757e-01, -4.8938e-02, -5.0370e-02, -1.1965e-01, -2.6330e-01,\n",
      "          1.0667e-01, -2.4615e-01, -1.9469e-01, -7.3108e-02,  1.1576e-01,\n",
      "         -2.2527e-01,  9.7775e-03,  1.1153e-02, -1.0897e-01, -8.3600e-02,\n",
      "         -1.6474e-01, -6.0707e-02,  3.5009e-01, -7.2000e-02,  2.7729e-01,\n",
      "          6.2410e-02,  4.1927e-02, -1.1430e-01, -2.5012e-01, -1.9859e-01,\n",
      "         -1.4253e-02,  5.3376e-02, -4.6784e-02,  5.6905e-02, -5.0841e-02,\n",
      "         -2.0965e-01,  3.3328e-01,  2.1890e-01, -9.3339e-02,  1.1859e-01,\n",
      "         -2.4047e-01,  2.3859e-02, -6.6788e-02,  1.6823e-01, -1.1979e-01,\n",
      "         -2.7962e-01, -2.2230e-01, -1.2553e-01,  9.1936e-02, -8.8022e-02,\n",
      "         -1.2962e-01, -1.9205e-01,  8.6503e-02,  9.4549e-02,  6.3554e-02,\n",
      "          9.7226e-02, -1.1651e-01, -1.8181e-01,  1.2346e-02, -1.4044e-01,\n",
      "         -8.9289e-02, -7.5024e-02,  2.1488e-01, -2.3721e-02, -1.2464e-01,\n",
      "          1.1769e-01,  2.2447e-02, -1.2076e-01,  1.7653e-02,  1.5364e-01,\n",
      "         -4.6385e-02, -1.9207e-01, -4.3027e-02,  1.5137e-02,  4.1110e-02,\n",
      "          3.6002e-01, -2.0610e-01,  8.1090e-03, -3.4754e-02],\n",
      "        [-2.4509e-01,  2.2309e-01, -2.4242e-01,  1.2197e-01,  1.9242e-02,\n",
      "         -2.0299e-01,  2.6227e-02,  2.2869e-01, -5.4205e-02,  9.4664e-02,\n",
      "         -1.3108e-02,  1.0760e-01,  1.1821e-02, -1.7179e-01,  2.0188e-01,\n",
      "         -2.3250e-01,  2.2733e-01, -9.7120e-02, -1.2681e-01, -1.7851e-02,\n",
      "          1.8872e-01, -6.0455e-02, -2.4004e-01,  5.1066e-02,  8.7042e-02,\n",
      "          1.2318e-01,  2.0103e-01, -3.2837e-02,  7.2149e-02, -5.7937e-02,\n",
      "         -2.3404e-01,  1.2372e-02, -9.4779e-02,  1.1898e-01, -6.5991e-02,\n",
      "          1.3095e-01, -4.3508e-02,  2.2410e-01,  3.1077e-01, -7.9698e-02,\n",
      "          1.6140e-01, -1.7130e-02, -2.5966e-02,  2.4065e-01, -1.6030e-01,\n",
      "          1.5816e-01,  1.1450e-01, -1.3414e-01,  7.9163e-02, -2.5881e-01,\n",
      "         -1.3931e-02, -5.7341e-02, -5.7790e-02, -1.3221e-01, -8.3406e-02,\n",
      "          1.3408e-01,  6.4371e-02, -3.1825e-02,  1.6011e-01, -2.4409e-01,\n",
      "          1.2964e-01,  3.7474e-02, -1.9219e-01,  1.3812e-01,  3.4857e-01,\n",
      "          6.3045e-02, -2.7537e-01, -8.9991e-02, -6.3072e-02, -1.2148e-01,\n",
      "          1.9767e-01,  1.6643e-01,  2.0812e-01, -8.2659e-02, -1.4367e-01,\n",
      "         -4.1882e-02, -2.0557e-01, -3.8379e-03, -1.6348e-01,  3.1442e-03,\n",
      "         -1.5822e-02,  5.3743e-02,  2.7789e-02, -1.1581e-01],\n",
      "        [-3.1495e-02,  3.9277e-02,  1.5422e-02, -1.3476e-01, -2.4994e-01,\n",
      "         -6.7240e-03,  1.0819e-01,  1.1843e-01,  7.9237e-02, -5.9682e-02,\n",
      "         -5.4119e-02, -1.2623e-01, -9.9708e-03,  8.2607e-03,  3.5359e-02,\n",
      "          1.4912e-01, -4.2770e-03,  9.7550e-02, -2.9200e-02, -1.5537e-01,\n",
      "         -2.5630e-01,  1.1356e-01, -2.7752e-01,  2.0120e-01, -2.3084e-01,\n",
      "         -8.6291e-02,  1.8497e-01, -8.7698e-02,  1.1175e-01,  2.7856e-01,\n",
      "          1.4525e-01,  8.4470e-02,  2.7911e-01, -5.2347e-03,  2.4267e-01,\n",
      "          5.8931e-02, -9.4673e-02,  1.5763e-01, -6.7088e-02,  2.4775e-01,\n",
      "         -1.5777e-01, -3.4307e-02,  1.3927e-01,  1.5181e-03,  1.1465e-01,\n",
      "          1.6855e-02, -4.2696e-02,  1.3109e-02, -9.3473e-02, -1.9673e-01,\n",
      "          2.1807e-01,  2.6161e-01, -5.2338e-03,  1.8578e-01,  7.5843e-02,\n",
      "         -6.3823e-02, -4.1529e-02, -7.0173e-02, -1.7741e-01, -1.4297e-01,\n",
      "          2.7430e-02,  8.8747e-02, -1.2512e-02, -1.2274e-01, -4.0269e-02,\n",
      "         -2.2946e-01, -1.6147e-01, -2.4535e-01,  1.4382e-01, -2.3468e-03,\n",
      "          1.5518e-01,  6.3600e-02, -7.0716e-02, -9.7528e-02,  6.4845e-02,\n",
      "         -9.4673e-02, -1.2853e-01,  1.0934e-01, -1.4942e-01,  1.6465e-02,\n",
      "          1.0967e-01,  1.0919e-01, -8.3560e-02, -2.9429e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4194,  0.0103,  0.0855,  0.1074,  0.3522, -0.1970,  0.2755, -0.0164,\n",
      "        -0.2154, -0.0637], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_adv = copy.deepcopy(net_ori) #am I doing correct? \n",
    "for param in net_adv.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5635cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_adv.parameters(), lr=0.001, momentum=0.9)\n",
    "PATH = './cifar_base_adv_pgd.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_Base_PGD\")\n",
    "pgd_attack = generate_adv(net_adv, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08ee62d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50]\t\n",
      "Epoch [1/50]\t Training Loss: 2.2839574600424606\t lr: 0.001\n",
      "Epoch [1/50]\t Validation Loss: 1.6474633835539032\t lr: 0.001\n",
      "Epoch [1/50]\t\n",
      "Epoch [2/50]\t Training Loss: 2.0984043212193053\t lr: 0.001\n",
      "Epoch [2/50]\t Validation Loss: 1.6317872488045995\t lr: 0.001\n",
      "Epoch [2/50]\t\n",
      "Epoch [3/50]\t Training Loss: 2.057575298087371\t lr: 0.001\n",
      "Epoch [3/50]\t Validation Loss: 1.6104123969621296\t lr: 0.001\n",
      "Epoch [3/50]\t\n",
      "Epoch [4/50]\t Training Loss: 2.0349581461123494\t lr: 0.001\n",
      "Epoch [4/50]\t Validation Loss: 1.607916465288476\t lr: 0.001\n",
      "Epoch [4/50]\t\n",
      "Epoch [5/50]\t Training Loss: 2.0203371078461942\t lr: 0.001\n",
      "Epoch [5/50]\t Validation Loss: 1.6162802388396444\t lr: 0.001\n",
      "Epoch [5/50]\t\n",
      "Epoch [6/50]\t Training Loss: 2.0091663547184155\t lr: 0.001\n",
      "Epoch [6/50]\t Validation Loss: 1.6130752729464182\t lr: 0.001\n",
      "Epoch [6/50]\t\n",
      "Epoch [7/50]\t Training Loss: 2.0004410115654205\t lr: 0.001\n",
      "Epoch [7/50]\t Validation Loss: 1.6110188281988795\t lr: 0.001\n",
      "Epoch [7/50]\t\n",
      "Epoch [8/50]\t Training Loss: 1.9943394011548718\t lr: 0.001\n",
      "Epoch [8/50]\t Validation Loss: 1.6006160521809059\t lr: 0.001\n",
      "Epoch [8/50]\t\n",
      "Epoch [9/50]\t Training Loss: 1.9874636410447337\t lr: 0.001\n",
      "Epoch [9/50]\t Validation Loss: 1.6089733295802828\t lr: 0.001\n",
      "Epoch [9/50]\t\n",
      "Epoch [10/50]\t Training Loss: 1.9840867766333967\t lr: 0.001\n",
      "Epoch [10/50]\t Validation Loss: 1.5957878858228274\t lr: 0.001\n",
      "Epoch [10/50]\t\n",
      "Epoch [11/50]\t Training Loss: 1.9789508108592704\t lr: 0.001\n",
      "Epoch [11/50]\t Validation Loss: 1.5947821321366709\t lr: 0.001\n",
      "Epoch [11/50]\t\n",
      "Epoch [12/50]\t Training Loss: 1.9753425292041906\t lr: 0.001\n",
      "Epoch [12/50]\t Validation Loss: 1.5984228577794908\t lr: 0.001\n",
      "Epoch [12/50]\t\n",
      "Epoch [13/50]\t Training Loss: 1.9713593663461983\t lr: 0.001\n",
      "Epoch [13/50]\t Validation Loss: 1.5898122636577752\t lr: 0.001\n",
      "Epoch [13/50]\t\n",
      "Epoch [14/50]\t Training Loss: 1.9683850799375178\t lr: 0.001\n",
      "Epoch [14/50]\t Validation Loss: 1.59368292440342\t lr: 0.001\n",
      "Epoch [14/50]\t\n",
      "Epoch [15/50]\t Training Loss: 1.9651139541660123\t lr: 0.001\n",
      "Epoch [15/50]\t Validation Loss: 1.5860974969743173\t lr: 0.001\n",
      "Epoch [15/50]\t\n",
      "Epoch [16/50]\t Training Loss: 1.9631261904831128\t lr: 0.001\n",
      "Epoch [16/50]\t Validation Loss: 1.5989535111415236\t lr: 0.001\n",
      "Epoch [16/50]\t\n",
      "Epoch [17/50]\t Training Loss: 1.9593806583863085\t lr: 0.001\n",
      "Epoch [17/50]\t Validation Loss: 1.5854516572590116\t lr: 0.001\n",
      "Epoch [17/50]\t\n",
      "Epoch [18/50]\t Training Loss: 1.9570802919700017\t lr: 0.001\n",
      "Epoch [18/50]\t Validation Loss: 1.5846654735034025\t lr: 0.001\n",
      "Epoch [18/50]\t\n",
      "Epoch [19/50]\t Training Loss: 1.954400042438751\t lr: 0.001\n",
      "Epoch [19/50]\t Validation Loss: 1.576434551915036\t lr: 0.001\n",
      "Epoch [19/50]\t\n",
      "Epoch [20/50]\t Training Loss: 1.9507624426156358\t lr: 0.001\n",
      "Epoch [20/50]\t Validation Loss: 1.5773715097692949\t lr: 0.001\n",
      "Epoch [20/50]\t\n",
      "Epoch [21/50]\t Training Loss: 1.9486651704134539\t lr: 0.001\n",
      "Epoch [21/50]\t Validation Loss: 1.5802309814887712\t lr: 0.001\n",
      "Epoch [21/50]\t\n",
      "Epoch [22/50]\t Training Loss: 1.9469734936419045\t lr: 0.001\n",
      "Epoch [22/50]\t Validation Loss: 1.5804965752589553\t lr: 0.001\n",
      "Epoch [22/50]\t\n",
      "Epoch [23/50]\t Training Loss: 1.9451245535974917\t lr: 0.001\n",
      "Epoch [23/50]\t Validation Loss: 1.5762458843520926\t lr: 0.001\n",
      "Epoch [23/50]\t\n",
      "Epoch [24/50]\t Training Loss: 1.9425429328323325\t lr: 0.001\n",
      "Epoch [24/50]\t Validation Loss: 1.5722465515136719\t lr: 0.001\n",
      "Epoch [24/50]\t\n",
      "Epoch [25/50]\t Training Loss: 1.9412158596546143\t lr: 0.001\n",
      "Epoch [25/50]\t Validation Loss: 1.5739427065547509\t lr: 0.001\n",
      "Epoch [25/50]\t\n",
      "Epoch [26/50]\t Training Loss: 1.9384691315843625\t lr: 0.001\n",
      "Epoch [26/50]\t Validation Loss: 1.568573984918715\t lr: 0.001\n",
      "Epoch [26/50]\t\n",
      "Epoch [27/50]\t Training Loss: 1.9374850253619806\t lr: 0.001\n",
      "Epoch [27/50]\t Validation Loss: 1.5676364943950991\t lr: 0.001\n",
      "Epoch [27/50]\t\n",
      "Epoch [28/50]\t Training Loss: 1.9356227198525158\t lr: 0.001\n",
      "Epoch [28/50]\t Validation Loss: 1.5616831221157992\t lr: 0.001\n",
      "Epoch [28/50]\t\n",
      "Epoch [29/50]\t Training Loss: 1.9344033399201415\t lr: 0.001\n",
      "Epoch [29/50]\t Validation Loss: 1.5677996692778189\t lr: 0.001\n",
      "Epoch [29/50]\t\n",
      "Epoch [30/50]\t Training Loss: 1.9313932346261067\t lr: 0.001\n",
      "Epoch [30/50]\t Validation Loss: 1.5653324398813369\t lr: 0.001\n",
      "Epoch [30/50]\t\n",
      "Epoch [31/50]\t Training Loss: 1.930498604884233\t lr: 0.001\n",
      "Epoch [31/50]\t Validation Loss: 1.5626388214811493\t lr: 0.001\n",
      "Epoch [31/50]\t\n",
      "Epoch [32/50]\t Training Loss: 1.9284438446659566\t lr: 0.001\n",
      "Epoch [32/50]\t Validation Loss: 1.5566214881365812\t lr: 0.001\n",
      "Epoch [32/50]\t\n",
      "Epoch [33/50]\t Training Loss: 1.9262759716004667\t lr: 0.001\n",
      "Epoch [33/50]\t Validation Loss: 1.5584106430222717\t lr: 0.001\n",
      "Epoch [33/50]\t\n",
      "Epoch [34/50]\t Training Loss: 1.9244987784749101\t lr: 0.001\n",
      "Epoch [34/50]\t Validation Loss: 1.5536436174489274\t lr: 0.001\n",
      "Epoch [34/50]\t\n",
      "Epoch [35/50]\t Training Loss: 1.9239592479013117\t lr: 0.001\n",
      "Epoch [35/50]\t Validation Loss: 1.5533411804633805\t lr: 0.001\n",
      "Epoch [35/50]\t\n",
      "Epoch [36/50]\t Training Loss: 1.9226942888611114\t lr: 0.001\n",
      "Epoch [36/50]\t Validation Loss: 1.562033241308188\t lr: 0.001\n",
      "Epoch [36/50]\t\n",
      "Epoch [37/50]\t Training Loss: 1.9202396378797644\t lr: 0.001\n",
      "Epoch [37/50]\t Validation Loss: 1.544292714022383\t lr: 0.001\n",
      "Epoch [37/50]\t\n",
      "Epoch [38/50]\t Training Loss: 1.9197568533670566\t lr: 0.001\n",
      "Epoch [38/50]\t Validation Loss: 1.5578461659105518\t lr: 0.001\n",
      "Epoch [38/50]\t\n",
      "Epoch [39/50]\t Training Loss: 1.9165658795315286\t lr: 0.001\n",
      "Epoch [39/50]\t Validation Loss: 1.5496910146520109\t lr: 0.001\n",
      "Epoch [39/50]\t\n",
      "Epoch [40/50]\t Training Loss: 1.9159416304829786\t lr: 0.001\n",
      "Epoch [40/50]\t Validation Loss: 1.5502362311640872\t lr: 0.001\n",
      "Epoch [40/50]\t\n",
      "Epoch [41/50]\t Training Loss: 1.9148915993892932\t lr: 0.001\n",
      "Epoch [41/50]\t Validation Loss: 1.547001401080361\t lr: 0.001\n",
      "Epoch [41/50]\t\n",
      "Epoch [42/50]\t Training Loss: 1.9135097094508997\t lr: 0.001\n",
      "Epoch [42/50]\t Validation Loss: 1.5462917934490155\t lr: 0.001\n",
      "Epoch [42/50]\t\n",
      "Epoch [43/50]\t Training Loss: 1.9119318052935783\t lr: 0.001\n",
      "Epoch [43/50]\t Validation Loss: 1.5542605119415476\t lr: 0.001\n",
      "Epoch [43/50]\t\n",
      "Epoch [44/50]\t Training Loss: 1.911325183670844\t lr: 0.001\n",
      "Epoch [44/50]\t Validation Loss: 1.5421845565868328\t lr: 0.001\n",
      "Epoch [44/50]\t\n",
      "Epoch [45/50]\t Training Loss: 1.9085061315380398\t lr: 0.001\n",
      "Epoch [45/50]\t Validation Loss: 1.5395370751996584\t lr: 0.001\n",
      "Epoch [45/50]\t\n",
      "Epoch [46/50]\t Training Loss: 1.9086775767528796\t lr: 0.001\n",
      "Epoch [46/50]\t Validation Loss: 1.5428422493270681\t lr: 0.001\n",
      "Epoch [46/50]\t\n",
      "Epoch [47/50]\t Training Loss: 1.9062269654725215\t lr: 0.001\n",
      "Epoch [47/50]\t Validation Loss: 1.546632875370074\t lr: 0.001\n",
      "Epoch [47/50]\t\n",
      "Epoch [48/50]\t Training Loss: 1.907093337734642\t lr: 0.001\n",
      "Epoch [48/50]\t Validation Loss: 1.5390047936499873\t lr: 0.001\n",
      "Epoch [48/50]\t\n",
      "Epoch [49/50]\t Training Loss: 1.9046109908682\t lr: 0.001\n",
      "Epoch [49/50]\t Validation Loss: 1.5365294278422488\t lr: 0.001\n",
      "Epoch [49/50]\t\n",
      "Epoch [50/50]\t Training Loss: 1.9033376487624614\t lr: 0.001\n",
      "Epoch [50/50]\t Validation Loss: 1.530217685276949\t lr: 0.001\n",
      "Epoch [49/50]\t Time Taken: 13.208516442775727 minutes\n"
     ]
    }
   ],
   "source": [
    "train(net_adv, train_loader, train_criterion,val_loader, val_criterion, \n",
    "              optimizer, 50, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0410a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "#test clean accuray\n",
    "test(val_loader, net_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b713f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 38.64 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "acc = clean_accuracy(net_adv, adv_images_fgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47b5b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 38.14 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "acc = clean_accuracy(net_adv, adv_images_vmifgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df98861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 38.71 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "acc = clean_accuracy(net_adv, adv_images_nifgsm_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43823993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model loaded]\n",
      "Acc: 38.57 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "acc = clean_accuracy(net_adv, adv_images_pgd_adv, labels)\n",
    "print('[Model loaded]')\n",
    "print('Acc: %2.2f %%'%(acc*100))\n",
    "print(\"adv model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d350815",
   "metadata": {},
   "source": [
    "# TODO: Adversarial Training by nifgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_adv_ni = copy.deepcopy(net_ori) #am I doing correct? \n",
    "for param in net_adv_ni.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_adv_ni.parameters(), lr=0.001, momentum=0.9)\n",
    "PATH = './cifar_base_adv_nifgsm.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_Base_nifgsm\")\n",
    "ni_attack = generate_adv(net_adv_ni, \"nifgsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5957488",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net_adv_ni, train_loader, train_criterion,val_loader, val_criterion, \n",
    "              optimizer, 50, writer, \n",
    "                 PATH, True, ni_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040f1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e8d1d9d",
   "metadata": {},
   "source": [
    "# TODO: Adversarial Training by vmifgsm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87070c",
   "metadata": {},
   "source": [
    "# TODO: Adversarial Training by fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca67d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
