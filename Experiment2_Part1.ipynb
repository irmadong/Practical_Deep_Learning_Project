{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d26265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c485356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TransferLearning of ATTACK --> \n",
    "# VS From Scratch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from model.baseline_model import *\n",
    "from trainer import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import robustbench\n",
    "#from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "from finetune_framework import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea736b",
   "metadata": {},
   "source": [
    "# Transfer Learning  Finetune FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182996c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/gm3044/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae61bd256124cb68a3d6ea7804d37b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/CIFAR-10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735055cdece548f5a99433be1ee3d5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/CIFAR-10/cifar-10-python.tar.gz to ./datasets/CIFAR-10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 10\n",
    "feature_extract = True\n",
    "\n",
    "model_transfer, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "train_dataset, val_dataset, train_loader, val_loader = CIFAR10(128, finetune = True, \n",
    "                                                               input_size = input_size, test_batch_size=128)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a4723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model_transfer = model_transfer.to(device)\n",
    "params_to_update = model_transfer.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_transfer.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_transfer.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_transfer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d81b931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "PATH = './cifar_resnet_transfer.pth'\n",
    "device = \"cuda\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"Standard_Resnet_Transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518abc2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 1.6231169136588837\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 1.007857088801227\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 1.2811612665195904\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 0.8829580153091044\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 1.217041926768125\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 0.8157951537566849\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 1.1810605672314345\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 0.7855270504951477\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 1.1646906643572366\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 0.7828300866899611\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 1.1466873434498488\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 0.7613090661507619\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 1.142103331320731\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 0.7426101678534399\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 1.1370464898741153\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 0.7379164869272257\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 1.1274885992564814\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 0.7256970367854154\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 1.1180889353422863\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 0.7153722349601456\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 1.1126579122470164\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 0.7204105454155162\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 1.1075595916079743\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 0.7188029666490192\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 1.1047784846152187\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 0.7120822947236556\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 1.1038065357586306\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 0.7134323312511927\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 1.1075063523124247\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 0.6989041913913775\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 1.0954542905473343\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 0.7035633861264096\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 1.102792999171235\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 0.7011985409108898\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 1.1035268367708797\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 0.6987162949163702\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 1.1007551991421243\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 0.685122385055204\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 1.0911597391528547\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 0.6958440247970291\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 1.0948564644969638\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 0.6978791846504694\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 1.0894228909021753\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 0.6935377275641961\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [23/100]\t Training Loss: 1.0922907840870226\t lr: 0.001\n",
      "Epoch [23/100]\t Validation Loss: 0.6860492810418334\t lr: 0.001\n",
      "Epoch [23/100]\t\n",
      "Epoch [24/100]\t Training Loss: 1.0959736172805357\t lr: 0.001\n",
      "Epoch [24/100]\t Validation Loss: 0.6884394748301446\t lr: 0.001\n",
      "Epoch [24/100]\t\n",
      "Epoch [25/100]\t Training Loss: 1.0859572407229783\t lr: 0.001\n",
      "Epoch [25/100]\t Validation Loss: 0.6947335525404049\t lr: 0.001\n",
      "Epoch [25/100]\t\n",
      "Epoch [26/100]\t Training Loss: 1.086898678403986\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 0.7049263210236272\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 1.090079187279772\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 0.6847562993629069\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 1.0853185604905229\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 0.6787742998781083\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 1.0893076175009198\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 0.6807219672806656\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 1.0868366866770303\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 0.6841882350324076\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 1.07483754590954\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 0.6788202841070634\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 1.080093092015942\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 0.6825731540028053\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 1.0780039321431114\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 0.6831808482544331\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 1.081948182009675\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 0.6806530514849892\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 1.0802048702374139\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 0.6851622748978531\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 1.0830551770032215\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 0.676257071993019\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 1.081762224512027\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 0.6910093388979948\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 1.0736045264222127\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 0.6708104421820822\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 1.0759414577728037\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 0.6689200333402127\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 1.0841055053579227\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 0.6747342136841786\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 1.0799476946406352\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 0.6751849126966694\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 1.0654929126315105\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 0.6899002232129061\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 1.0753703324691108\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 0.6827874357187296\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 1.0723029888804307\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 0.6781853437423706\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 1.076948339676918\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 0.671508322033701\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 1.0713770743221274\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 0.6872004828875578\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 1.072901529729214\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 0.6738211399392237\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 1.0746524916280566\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 0.6761470365373394\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 1.0762144630522374\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 0.6759658063514323\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 1.0788834066037327\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 0.6754734316204167\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 1.0761733277679404\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 0.6811491307578509\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 1.0744532247638459\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 0.6695852162717264\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 1.0738878341587\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 0.6773948744882511\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 1.064890561963591\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 0.6684276699265347\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 1.0697488736008745\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 0.671099867247328\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 1.0685668630368264\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 0.6689319520057002\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 1.0632014945339974\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 0.6697410533699808\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 1.0733488542039682\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 0.6678724654867679\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 1.071562177994672\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 0.6764036831976492\t lr: 0.001\n",
      "Epoch [59/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]\t Training Loss: 1.069207685530338\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 0.6770626532880566\t lr: 0.001\n",
      "Epoch [60/100]\t\n",
      "Epoch [61/100]\t Training Loss: 1.067069401521512\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 0.6637019605576238\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 1.0724254075218649\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 0.6738717473005946\t lr: 0.001\n",
      "Epoch [62/100]\t\n",
      "Epoch [63/100]\t Training Loss: 1.0695636359322103\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 0.6769446602350548\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 1.0697336907277022\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 0.6769097949130626\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 1.0684480115275858\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 0.6765231014807013\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 1.0692082399602436\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 0.6804313606853727\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 1.07025819330874\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 0.6687033881869497\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 1.0689607402857613\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 0.6750452857983263\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 1.0681231614878721\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 0.6654517616652236\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 1.0711110062001612\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 0.668665466429312\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 1.0681566871950388\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 0.6655053149295759\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 1.0749454554694389\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 0.678397470071346\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 1.0658878809045953\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 0.6671351488632492\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 1.0744787274724077\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 0.6651285181317148\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 1.0617063986066053\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 0.6722930300084851\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 1.0701546004361204\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 0.6716742477839506\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 1.0649832479484247\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 0.6686235756813725\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 1.0666489744430308\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 0.6672864288468904\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 1.072132294287767\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 0.6675467196899124\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 1.062257848737185\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 0.671335445174688\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 1.0657707346064964\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 0.669834720560267\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 1.0701178287910988\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 0.6690768969209888\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 1.0697233407088862\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 0.6550060608718968\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 1.0632678169728544\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 0.6681530468071564\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 1.0688145236895823\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 0.658968872661832\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 1.0656981547470288\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 0.6686502566820458\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 1.0662505344661606\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 0.6658222384845154\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 1.0648505456002473\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 0.660918270108066\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 1.0699439228648115\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 0.6680864737003664\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 1.0633887198879897\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 0.6610365521304215\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 1.0666421192991153\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 0.6673980574064617\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 1.068961509200923\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 0.6591028099573111\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 1.0670297122977275\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 0.6605421557456632\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 1.0624240966099303\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 0.6644676237166682\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 1.0701563189096768\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 0.6600068194579475\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 1.0625972848414156\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 0.6677257611027246\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 1.0594516006272163\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 0.6683536820773837\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 1.058752813759972\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 0.6649888282335257\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 1.0644775697642275\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 0.6662013145941722\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 1.065312709802252\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 0.6708588366267048\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 191.02482891480128 minutes\n"
     ]
    }
   ],
   "source": [
    "train(model_transfer, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_transfer, 100, writer, \n",
    "                 PATH, False, None, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd00d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, model_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335ab5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 0.00 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_transfer, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, model_transfer, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0153121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 18.76 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_transfer, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, model_transfer, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "414692d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 2.02 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_transfer, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, model_transfer, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c750e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 0.00 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_transfer, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, model_transfer, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4802c",
   "metadata": {},
   "source": [
    "# Adversarial Training on PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9addb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_adv = copy.deepcopy(model_transfer) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f7465c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = net_adv.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net_adv.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in net_adv.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = './cifar_trans_resnet_adv_pgd.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_trans_resnet_PGD\")\n",
    "pgd_attack = generate_adv(net_adv, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045da609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 5.637540827626768\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 2.4945161704775654\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 2.688544991681033\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 2.3034445847137066\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 2.331932678247047\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 2.3041754010357436\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 2.3292663572999217\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 2.3032776675646818\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 2.331259251250635\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 2.3027724103082585\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 2.3305080046739115\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 2.3011498571951177\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 2.328952040513763\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 2.3042136566548406\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 2.3305871559835762\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 2.300532748427572\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 2.330931931810306\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 2.3067047958132587\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 2.3302675525245764\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 2.3021818354159973\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 2.3310305639301117\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 2.3031471620632122\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 2.3287520158626234\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 2.3023225567008874\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 2.330022761279055\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 2.306114574021931\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 2.328296445519723\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 2.3006609029407743\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 2.3294632849485977\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 2.300996538958972\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 2.3319037643539935\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 2.302970961679386\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 2.329159212844146\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 2.30173691314987\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 2.3316173151021116\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 2.3033549544177476\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 2.329948320413185\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 2.303812763358973\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 2.3303782708199736\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 2.305692624442185\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 2.3303628882483753\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 2.3037417870533616\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 2.33028097530765\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 2.3019662537152255\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [23/100]\t Training Loss: 2.329800140522325\t lr: 0.001\n",
      "Epoch [23/100]\t Validation Loss: 2.300643975221658\t lr: 0.001\n",
      "Epoch [23/100]\t\n",
      "Epoch [24/100]\t Training Loss: 2.330185782269139\t lr: 0.001\n",
      "Epoch [24/100]\t Validation Loss: 2.302575274358822\t lr: 0.001\n",
      "Epoch [24/100]\t\n",
      "Epoch [25/100]\t Training Loss: 2.329513860785443\t lr: 0.001\n",
      "Epoch [25/100]\t Validation Loss: 2.3014131678810603\t lr: 0.001\n",
      "Epoch [25/100]\t\n",
      "Epoch [26/100]\t Training Loss: 2.329006079212784\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 2.300523371636113\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 2.3309331403668883\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 2.302326084692267\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 2.3292340220087935\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 2.304671984684618\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 2.3307282973433394\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 2.299717860885813\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 2.328948628871947\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 2.3047798434390296\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 2.3303973290621474\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 2.3043172540543955\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 2.329548727216013\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 2.3018689004680777\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 2.3304327534287785\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 2.3016123620769644\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 2.3296392829826726\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 2.3029929474939275\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 2.330800863178185\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 2.304100564763516\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 2.328563142005745\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 2.300580637364448\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 2.3289599808890498\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 2.299166365514828\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 2.3303943101097557\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 2.301959472366526\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 2.3294871731487383\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 2.3020938468884817\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 2.329716467186618\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 2.30083249792268\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 2.3313051672542797\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 2.300389371340788\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 2.330988624211772\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 2.3022281519974332\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 2.331486463546753\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 2.3013447055333778\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 2.328817143159754\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 2.3029882606071763\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 2.328624082648236\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 2.3023109556753423\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 2.3307663711440534\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 2.3024020617521264\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 2.329469299682266\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 2.302484180353865\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 2.330332995680592\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 2.3024929535539846\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 2.329855408509979\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 2.306632826599894\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 2.329563978078115\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 2.3011387269708177\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 2.32995529187\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 2.303122834314274\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 2.328521559000625\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 2.2992155582089966\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 2.3285529942768615\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 2.305286000046549\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 2.330576063726869\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 2.302761032611509\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 2.3293891184775117\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 2.3048040595235704\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 2.3313620407563036\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 2.303724243671079\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 2.3287883658543267\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 2.3042174924778034\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 2.328275418342532\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 2.3023909134200857\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 2.330211206470304\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 2.3050628825079036\t lr: 0.001\n",
      "Epoch [59/100]\t\n",
      "Epoch [60/100]\t Training Loss: 2.328878324659889\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 2.302343036555037\t lr: 0.001\n",
      "Epoch [60/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]\t Training Loss: 2.3310230003903283\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 2.301942203618303\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 2.329626933388088\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 2.307575446140917\t lr: 0.001\n",
      "Epoch [62/100]\t\n",
      "Epoch [63/100]\t Training Loss: 2.3292656127754077\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 2.302678977386861\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 2.329783272560295\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 2.3014297364633296\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 2.3292187430974467\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 2.301723383649995\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 2.329780163362508\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 2.3043304515790335\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 2.3314465677646723\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 2.301847946794727\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 2.3304897330301193\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 2.3021182621581646\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 2.328261766897138\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 2.302563597884359\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 2.329147454722763\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 2.3060192729853375\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 2.328488807239191\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 2.30427951752385\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 2.33048429574503\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 2.305414513696598\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 2.3292893399972745\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 2.3020923348921762\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 2.330801166841746\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 2.303851034067854\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 2.3298720447608576\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 2.3028804320323317\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 2.328759374520968\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 2.3055319122121305\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 2.329275235495604\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 2.300598431237136\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 2.3307797012426663\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 2.3070766050604323\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 2.331109112181017\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 2.3049153647845304\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 2.32873004720644\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 2.3034806583501117\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 2.3291343258469914\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 2.3019248382954656\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 2.3287221604905777\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 2.2999332464194\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 2.329316773987792\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 2.30528738830663\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 2.331298617145899\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 2.301479034785983\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 2.3285874454566584\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 2.3017616392690923\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 2.3295086039911452\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 2.3015506659881977\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 2.328563919457633\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 2.303689537169058\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 2.3288039222092887\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 2.3020176042484333\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 2.3305350203648247\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 2.3026415637776823\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 2.328817621216445\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 2.3032676298407058\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 2.329623124788484\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 2.3034004652047457\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 2.329702919401476\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 2.3026247869564007\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 2.3282216961121622\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 2.3019244550149653\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 2.3305750106606644\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 2.304923431782783\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 2.3283841914837926\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 2.302554465547393\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 2.3291851651028295\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 2.3030893681924556\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 2.330551149290236\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 2.303851900221426\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 2.330719125850121\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 2.302887264686295\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 2.3293955862674567\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 2.304043027419078\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 2.329064932625617\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 2.303370765492886\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 1049.3970776677131 minutes\n"
     ]
    }
   ],
   "source": [
    "train(net_adv, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_adv, 100, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e0994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, net_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "994d4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 10.06 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_transfer, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, net_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3491553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 10.07 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_transfer, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, net_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4feb968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 10.02 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_transfer, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, net_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc08d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 10.00 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_transfer, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, net_adv, \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
