{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98059ee5",
   "metadata": {},
   "source": [
    "# Resnet 18 from scratch on standard training and attacks on CIFAR 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d26265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c485356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1+cu110\n",
      "Torchvision Version:  0.8.2+cu110\n"
     ]
    }
   ],
   "source": [
    "#TransferLearning of ATTACK --> \n",
    "# VS From Scratch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from model.baseline_model import *\n",
    "from trainer import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import robustbench\n",
    "#from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "from finetune_framework import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d035d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./datasets/CIFAR-100/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022341012954711914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b566f52707b4e6192f54bba8cdb6b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/CIFAR-100/cifar-100-python.tar.gz to ./datasets/CIFAR-100\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 100\n",
    "feature_extract = False\n",
    "\n",
    "model_scratch, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "train_dataset, val_dataset, train_loader, val_loader = CIFAR100(128, finetune = True, \n",
    "                                                               input_size = input_size, test_batch_size=128)\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbea6acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e62cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model_scratch = model_scratch.to(device)\n",
    "params_to_update = model_scratch.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_scratch = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82480b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "PATH = './cifar_resnet_scratch_100.pth'\n",
    "device = \"cuda\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"Standard_Resnet_Scratch_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b29fcc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 4.281087502189305\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 4.0268026816694045\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 3.9563587657021135\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 3.8379239975651607\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 3.8336323545412028\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 3.697008836118481\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 3.7369757997410376\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 3.6083407734013813\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 3.661471131512576\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 3.541160631783401\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 3.6023108288455195\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 3.480535781836208\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 3.543496634954077\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 3.394083195094821\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 3.4896300021949633\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 3.3406296017803725\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 3.4378042153995056\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 3.2919922025897836\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 3.3865417745107274\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 3.2470663106894193\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 3.343123807321729\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 3.1488231707222853\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 3.2896794419154487\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 3.105310542674004\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 3.2494159537508054\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 3.040770138366313\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 3.2105186272155293\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 3.036710690848435\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 3.168096289915197\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 2.985634103606019\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 3.136866795132532\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 2.978224597399748\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 3.087818020749885\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 2.8843952462643005\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 3.0520762147196114\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 2.8836282597312444\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 3.028922676125451\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 2.8223386082468154\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 2.9872924872981312\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 2.8085777125781095\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 2.952777950355159\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 2.7513717790193195\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 2.9062530189523916\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 2.716000065018859\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [23/100]\t Training Loss: 2.8778339548184135\t lr: 0.001\n",
      "Epoch [23/100]\t Validation Loss: 2.678078835523581\t lr: 0.001\n",
      "Epoch [23/100]\t\n",
      "Epoch [24/100]\t Training Loss: 2.833369134332213\t lr: 0.001\n",
      "Epoch [24/100]\t Validation Loss: 2.6599702261671236\t lr: 0.001\n",
      "Epoch [24/100]\t\n",
      "Epoch [25/100]\t Training Loss: 2.8026788813988572\t lr: 0.001\n",
      "Epoch [25/100]\t Validation Loss: 2.578773960282531\t lr: 0.001\n",
      "Epoch [25/100]\t\n",
      "Epoch [26/100]\t Training Loss: 2.7785979634355704\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 2.5803723003290875\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 2.7375922794537164\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 2.5616554987581472\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 2.7179245491466864\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 2.4892157150220267\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 2.6853113204926786\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 2.4600417100930514\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 2.656602506442448\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 2.4942299776439425\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 2.623245397797021\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 2.4476278733603563\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 2.5932069532096844\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 2.3921485007563725\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 2.5699133214438357\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 2.4135719009592562\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 2.536113341446118\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 2.3517492903938777\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 2.5119043384366635\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 2.3540832000442697\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 2.482688887344907\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 2.281879373743564\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 2.461303023121241\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 2.3833370782152006\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 2.435174693231997\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 2.233005905453163\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 2.40855342591815\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 2.263241737703734\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 2.389192634531299\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 2.2068204894850525\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 2.3600670434629825\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 2.1672692359248296\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 2.3332740778813275\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 2.187379068966153\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 2.3130417449395066\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 2.133536254303365\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 2.2899847997119056\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 2.134707847728005\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 2.2538910143820527\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 2.085421743272226\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 2.2511959725328725\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 2.043938636779785\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 2.226601413448753\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 2.0131584375719482\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 2.2024781764925594\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 2.0871209721022015\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 2.196333823301603\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 1.9742002004309545\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 2.1664958487996056\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 1.9607497227342823\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 2.13945034946627\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 1.9471249376671225\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 2.130052066215164\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 1.9488877435273761\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 2.1120314198686643\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 1.9415978600707235\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 2.08491052477561\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 1.9515252249150337\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 2.069830367022463\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 1.899909730199017\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 2.044345824309932\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 1.9201457741894299\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 2.0235071264569413\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 1.8860586323315585\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 2.02825320529206\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 1.8792796210397649\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 1.9965268843009343\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 1.8248805697960189\t lr: 0.001\n",
      "Epoch [59/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]\t Training Loss: 1.9853497313721407\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 1.8492798971224436\t lr: 0.001\n",
      "Epoch [60/100]\t\n",
      "Epoch [61/100]\t Training Loss: 1.967300393697246\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 1.8423214532152008\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 1.9443874020710625\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 1.8205428621436976\t lr: 0.001\n",
      "Epoch [62/100]\t\n",
      "Epoch [63/100]\t Training Loss: 1.928411097477769\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 1.7704804728302774\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 1.9143045692492628\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 1.785844952245302\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 1.9120185808147616\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 1.7999907490573352\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 1.8831863141120853\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 1.7379785338534584\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 1.8714162782025154\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 1.758028650585609\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 1.8531255670215772\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 1.746329804010029\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 1.8373584890609507\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 1.7129455835004397\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 1.825841550022135\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 1.745927125592775\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 1.8169979210704794\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 1.7454393498505218\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 1.7981802100110846\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 1.6918546730958963\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 1.7923502434245155\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 1.706470865237562\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 1.7791316564125783\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 1.6772195749644991\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 1.7588985914464497\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 1.6789814354498176\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 1.7452877811763599\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 1.6349921166142332\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 1.7276441682025294\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 1.7157945240600199\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 1.7181604545744484\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 1.6165156168273733\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 1.7117690729058308\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 1.648638444610789\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 1.6920752744845418\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 1.6501975859267801\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 1.6905150636077841\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 1.5966140891932235\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 1.6657096391443706\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 1.6037096117116227\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 1.6642296838638422\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 1.6089249185368986\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 1.6425220365719417\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 1.6538920613783825\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 1.6279460703930282\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 1.5796098724196228\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 1.619671615493267\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 1.5643192974826958\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 1.6258541741944335\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 1.60911829411229\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 1.5967965418725367\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 1.6119121026389207\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 1.5900052682213162\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 1.5772313558602635\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 1.5876058288242505\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 1.5662215570860272\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 1.5747915402702664\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 1.547677539571931\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 1.5619157885041688\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 1.5658842732634726\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 1.5512672229800992\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 1.5661105400399318\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 1.5304570036471044\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 1.5320653583430037\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 1.5288892447796014\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 1.5854844971548152\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 1.529148579253565\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 1.5011449599567848\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 1.5069383974270443\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 1.540057360371457\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 1.500966878803185\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 1.5168884306014339\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 1.4944906414622237\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 1.5237641696688495\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 1.480934931494086\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 1.5227442134784748\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 373.9856216669083 minutes\n"
     ]
    }
   ],
   "source": [
    "train(model_scratch, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_scratch, 100, writer, \n",
    "                 PATH, False, None, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd00d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, model_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335ab5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 1.72 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0153121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 9.63 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414692d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 3.58 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c750e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 1.90 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca31be2",
   "metadata": {},
   "source": [
    "# ResNet 18 from scratch on adversarial training and attacks on CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9addb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_scratch_adv = copy.deepcopy(model_scratch) #am I doing correct? \n",
    "# for param in net_adv.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7465c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = net_scratch_adv.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net_scratch_adv.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "train_criterion = nn.CrossEntropyLoss() \n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = './cifar_trans_resnet_scratch_adv_pgd.pth' #to do change to 100 \n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_trans_resnet_scratch_PGD\")\n",
    "pgd_attack = generate_adv(model_scratch, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045da609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 3.1038518092211556\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 31.664396117005168\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 2.7384813709941973\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 48.088782877861696\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 2.6230291643410997\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 48.43528839304477\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 2.544090086846705\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 48.8614333430423\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 2.494838892346453\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 51.19081535822229\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 2.449356273616976\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 51.079985316795636\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 2.4091631661900474\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 49.08472104615803\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 2.378824360535273\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 48.71462172496168\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 2.352613561293658\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 52.225839494149895\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 2.320157391640841\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 52.86374958859214\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 2.2991688611257413\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 50.08322071123727\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 2.26869551117158\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 52.33911528768419\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 2.2697953458332343\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 52.46820768525329\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 2.2202713873685167\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 49.74752406832538\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 2.213438294427779\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 57.863671894314926\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 2.1881552370612884\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 53.11074824272832\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 2.158082926364811\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 55.168904461438146\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 2.1387286119143982\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 49.872608715974835\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 2.121450675418005\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 46.058439278904395\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 2.0890598900787665\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 50.44811147375952\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 2.066798408318054\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 54.56109532223472\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 2.023162633866605\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 46.25669252419774\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [23/100]\t Training Loss: 1.9719282641740101\t lr: 0.001\n",
      "Epoch [23/100]\t Validation Loss: 49.06328471702865\t lr: 0.001\n",
      "Epoch [23/100]\t\n",
      "Epoch [24/100]\t Training Loss: 1.9656955622651082\t lr: 0.001\n",
      "Epoch [24/100]\t Validation Loss: 49.278713419467586\t lr: 0.001\n",
      "Epoch [24/100]\t\n",
      "Epoch [25/100]\t Training Loss: 1.921651839905078\t lr: 0.001\n",
      "Epoch [25/100]\t Validation Loss: 45.663244030143645\t lr: 0.001\n",
      "Epoch [25/100]\t\n",
      "Epoch [26/100]\t Training Loss: 1.8849265898585015\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 45.594640659380566\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 1.8606264069866951\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 46.14438266995587\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 1.8399746600929123\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 43.47185579130921\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 1.7981933166303903\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 46.08467063420935\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 1.7712284332651007\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 41.82895742488813\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 1.7478790581988557\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 51.668721307682084\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 1.7188623570420247\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 56.17776107788086\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 1.6977784231190791\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 51.296940719025045\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 1.6722120885044107\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 49.850978416732595\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 1.6356524604055889\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 51.83482988574837\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 1.6178081651477862\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 53.156398869767976\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 1.6070222680830895\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 56.313566956339\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 1.5845227403104152\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 51.128233028363574\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 1.573691944027191\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 45.38981058627744\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 1.539287401282269\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 50.16001993493189\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 1.5287794377797705\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 50.5295774725419\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 1.516701357139041\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 55.12488893919353\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 1.5013266323167649\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 57.138872750197784\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 1.4758590420188806\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 49.80982918075368\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 1.4592301775427425\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 52.61088798619524\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 1.4497155484640996\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 55.44046715845035\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 1.4295126211917615\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 55.98877175246613\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 1.406431024336754\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 62.15428972847854\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 1.3983046630459368\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 59.46943379655669\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 1.3876207225462969\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 63.38232537764537\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 1.3768419005986674\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 63.871464644806295\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 1.345155248099276\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 54.49638670909254\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 1.3401243787287447\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 51.98046759110463\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 1.3201053790424182\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 61.708356253708466\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 1.3135273523647766\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 57.75807875621168\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 1.2968953835689807\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 56.5554529986804\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 1.2840853107859715\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 62.71030952357039\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 1.2560269652730058\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 68.05256744577915\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 1.2634320602087719\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 65.94076765036282\t lr: 0.001\n",
      "Epoch [59/100]\t\n",
      "Epoch [60/100]\t Training Loss: 1.2529282132378015\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 65.4333084685893\t lr: 0.001\n",
      "Epoch [60/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]\t Training Loss: 1.2372887020220842\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 67.0816765797289\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 1.2389980845744042\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 67.47748184204102\t lr: 0.001\n",
      "Epoch [62/100]\t\n",
      "Epoch [63/100]\t Training Loss: 1.2130697229329277\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 58.50753576544267\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 1.1956222848514158\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 58.214483236964746\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 1.1887955351558792\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 66.11614975748184\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 1.1785911507618703\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 60.08599742454818\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 1.176644406202809\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 60.74316782890996\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 1.1684040605564556\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 61.63146359407449\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 1.1520934239067995\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 65.94958858248553\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 1.1487247852413245\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 57.781181287161914\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 1.1300268382062693\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 58.554269428494614\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 1.11897527058716\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 57.3860193566431\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 1.11946996490059\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 62.67521097690244\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 1.1040822342228707\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 64.82411869869956\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 1.0881250276589942\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 59.470743976061854\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 1.0844062827432248\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 49.546420954450774\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 1.0836316084922732\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 56.2849930389018\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 1.0630969946341746\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 65.23975333684608\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 1.0571266516395237\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 52.61568069458008\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 1.0434678001781863\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 55.17968677569039\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 1.0342096322027923\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 58.23865069618708\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 1.0382261652775737\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 48.76195666156238\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 1.024214739232417\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 44.3292741896231\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 1.011147218134702\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 58.87736062158512\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 1.0134076037065451\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 55.223202379443975\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 1.00167746693277\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 50.84031445467019\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 0.9931559923969572\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 57.566104406042946\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 0.983651759069594\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 61.69178844403617\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 0.9780394122423723\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 47.0436958119839\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 0.9702857868445803\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 54.49696784683421\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 0.9539037119702\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 60.26310343682012\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 0.9629013395065542\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 56.33812153490284\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 0.9536770408415733\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 48.80508306962025\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 0.9489405325916417\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 61.63460395909563\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 0.9398615610264146\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 52.71930646292771\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 0.925951262111859\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 51.04469869106631\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 0.9253335666778447\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 58.77072133897226\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 0.925585765515447\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 56.91060237643085\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 0.9074478097583937\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 70.28126559680021\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 0.8988737995972109\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 64.4349586873115\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 2797.355981926123 minutes\n"
     ]
    }
   ],
   "source": [
    "train(net_scratch_adv, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_adv, 100, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84bfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1+cu110\n",
      "Torchvision Version:  0.8.2+cu110\n",
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 1 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, net_scratch_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0405fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 64.19 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca255b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 58.32 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d7c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 67.70 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e540e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 70.20 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cd8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
