{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98059ee5",
   "metadata": {},
   "source": [
    "# TODO Compared with from scratch standard training and attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d26265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c485356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1+cu110\n",
      "Torchvision Version:  0.8.2+cu110\n"
     ]
    }
   ],
   "source": [
    "#TransferLearning of ATTACK --> \n",
    "# VS From Scratch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from model.baseline_model import *\n",
    "from trainer import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import robustbench\n",
    "#from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "from finetune_framework import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d035d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./datasets/CIFAR-100/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022341012954711914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b566f52707b4e6192f54bba8cdb6b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/CIFAR-100/cifar-100-python.tar.gz to ./datasets/CIFAR-100\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 100\n",
    "feature_extract = False\n",
    "\n",
    "model_scratch, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "train_dataset, val_dataset, train_loader, val_loader = CIFAR100(128, finetune = True, \n",
    "                                                               input_size = input_size, test_batch_size=128)\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e62cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model_scratch = model_scratch.to(device)\n",
    "params_to_update = model_scratch.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_scratch = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82480b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "PATH = './cifar_resnet_scratch_100.pth'\n",
    "device = \"cuda\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"Standard_Resnet_Scratch_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fcc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n"
     ]
    }
   ],
   "source": [
    "train(model_scratch, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_scratch, 100, writer, \n",
    "                 PATH, False, None, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd00d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, model_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ab5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0153121",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414692d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca31be2",
   "metadata": {},
   "source": [
    "# TODO Compared with from scratch adversarial training and attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9addb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_scratch_adv = copy.deepcopy(model_scratch) #am I doing correct? \n",
    "# for param in net_adv.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7465c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = net_scratch_adv.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net_scratch_adv.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = './cifar_trans_resnet_scratch_adv_pgd.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_trans_resnet_scratch_PGD\")\n",
    "pgd_attack = generate_adv(net_scratch_adv, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045da609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net_scratch_adv, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_adv, 100, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, net_scratch_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca255b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e540e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cd8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
