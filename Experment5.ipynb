{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98059ee5",
   "metadata": {},
   "source": [
    "# TODO Compared with from scratch standard training and attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d26265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c485356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1+cu110\n",
      "Torchvision Version:  0.8.2+cu110\n"
     ]
    }
   ],
   "source": [
    "#TransferLearning of ATTACK --> \n",
    "# VS From Scratch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "from model.baseline_model import *\n",
    "from trainer import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import robustbench\n",
    "#from robustbench.data import load_cifar10\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "from finetune_framework import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d035d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 10\n",
    "feature_extract = False\n",
    "\n",
    "model_scratch, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "train_dataset, val_dataset, train_loader, val_loader = CIFAR10(128, finetune = True, \n",
    "                                                               input_size = input_size, test_batch_size=128)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e62cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "model_scratch = model_scratch.to(device)\n",
    "params_to_update = model_scratch.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_scratch = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d82480b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "PATH = './cifar_resnet_scratch.pth'\n",
    "device = \"cuda\"\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"Standard_Resnet_Scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29fcc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 1.920101451751826\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 1.7191996257516402\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 1.7279964761660838\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 1.5322630586503427\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 1.6405305661203917\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 1.460173717027978\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 1.5757409812849197\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 1.4013633335692972\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 1.5157668130172184\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 1.3420712057548234\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 1.4632819232428471\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 1.2792894063116629\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 1.4183214271769804\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 1.2978188508673558\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 1.3755991181449208\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 1.305946777138529\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 1.3333236585797557\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 1.1555667798730391\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 1.2957859807612035\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 1.2414053889769543\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 1.267854337649577\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 1.0570437704460531\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 1.2290281497913857\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 1.0439042667799359\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 1.1996421245357873\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 1.0676484847370582\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 1.1745151444469266\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 1.0014766220805011\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 1.1527730511582417\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 1.0154301607156102\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 1.1238412910410205\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 0.9831450604185273\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 1.1001608790948874\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 0.9494602778289891\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 1.0698010788854126\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 0.9029759130900419\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 1.0564458842777535\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 0.9059475215175484\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 1.0330721914310894\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 0.8425198680237879\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 1.013327129509138\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 0.8454968687854235\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 0.9920272531411837\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 0.8479579490951344\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [23/100]\t Training Loss: 0.9849806921866239\t lr: 0.001\n",
      "Epoch [23/100]\t Validation Loss: 0.7898361992232407\t lr: 0.001\n",
      "Epoch [23/100]\t\n",
      "Epoch [24/100]\t Training Loss: 0.9573141062046255\t lr: 0.001\n",
      "Epoch [24/100]\t Validation Loss: 0.8227232981331741\t lr: 0.001\n",
      "Epoch [24/100]\t\n",
      "Epoch [25/100]\t Training Loss: 0.9584551523713505\t lr: 0.001\n",
      "Epoch [25/100]\t Validation Loss: 0.8532717937155615\t lr: 0.001\n",
      "Epoch [25/100]\t\n",
      "Epoch [26/100]\t Training Loss: 0.9310321739262633\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 0.7651574656933169\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 0.9205194597354021\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 0.8571959960309765\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 0.9177338378813565\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 0.7586055254634423\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 0.8986588910107722\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 0.8122349026836927\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 0.8856521198511733\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 0.7485663128804557\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 0.8738065334537145\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 0.7563776690748674\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 0.8570688398902678\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 0.7748489832576317\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 0.850249370345679\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 0.7363490371764461\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 0.8453049880769247\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 0.7034740561171423\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 0.837156852797779\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 0.7122351629070088\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 0.8221733861262231\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 0.6966925289811967\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 0.8199274664949578\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 0.6841737446905691\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 0.8097580352707592\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 0.6674258301529703\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 0.7979688458430493\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 0.6208868630324738\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 0.792647183551203\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 0.6645573411561265\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 0.7839896592032879\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 0.634373965519893\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 0.7784228620626737\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 0.7327012514011769\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 0.7638235708026935\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 0.6478979844081251\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 0.7569654702835376\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 0.6396245941331115\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 0.7561697240375802\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 0.6027864625182333\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 0.7427398663042756\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 0.5821325688422481\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 0.7411960058504968\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 0.5804386172868028\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 0.731825044621592\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 0.5948558366751369\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 0.723881144048003\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 0.5860054938099052\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 0.7272801990704159\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 0.5799204643014111\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 0.7126046261366676\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 0.6934093282192568\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 0.7061143745394314\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 0.5449944681759122\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 0.6970636388834786\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 0.5827897462663771\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 0.6896872807036886\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 0.6293056113055989\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 0.689891740489189\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 0.5842103033880645\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 0.6844934202216165\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 0.5248672354824936\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 0.6823040151687534\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 0.6840533018112183\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 0.6759756364480919\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 0.5152671940719025\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 0.669991458468425\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 0.631289262937594\t lr: 0.001\n",
      "Epoch [59/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]\t Training Loss: 0.6679742376670204\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 0.5474943582770191\t lr: 0.001\n",
      "Epoch [60/100]\t\n",
      "Epoch [61/100]\t Training Loss: 0.6557074269980115\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 0.5204248201997974\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 0.6617547073175231\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 0.5567510067662106\t lr: 0.001\n",
      "Epoch [62/100]\t\n",
      "Epoch [63/100]\t Training Loss: 0.6529458463191986\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 0.520437446198886\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 0.6516531833145015\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 0.5944521842123587\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 0.648900988233059\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 0.5386933405188066\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 0.6415800507873526\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 0.5405959196483032\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 0.6339339601719166\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 0.5207531855830664\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 0.6322447077545059\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 0.6382674401319479\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 0.6256655913484676\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 0.49850758382036714\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 0.6159108557816967\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 0.5422026390516306\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 0.6201564197802483\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 0.5202493829817711\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 0.6155649326798861\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 0.496174566542046\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 0.6076810806608566\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 0.5208456127703944\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 0.603401375548614\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 0.5478998392443114\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 0.5959439193806075\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 0.5597674314734302\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 0.5972538207040723\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 0.4932499844816667\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 0.5865028252077225\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 0.4927534330872041\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 0.5883640358057778\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 0.49255411496645285\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 0.5869068148953226\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 0.5084259204472168\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 0.5781159399415526\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 0.4617802644077736\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 0.578459172526284\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 0.45650900277910356\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 0.5767045798509017\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 0.5008844974674757\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 0.5659562574170739\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 0.4788076902114892\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 0.5650587963783528\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 0.47208063398735434\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 0.5615739072375285\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 0.5146800585185425\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 0.5668039819621065\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 0.4932207616069649\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 0.5629201434609835\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 0.5007866766256622\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 0.5571579026901509\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 0.5293864690804784\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 0.5438501011685032\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 0.47711657798742946\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 0.5519100862085972\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 0.4867694955083388\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 0.5466021228476864\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 0.45008251976363267\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 0.5479895980919108\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 0.4468386229834979\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 0.5348942664730579\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 0.44629359754580483\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 0.5372808979600286\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 0.43853601794454117\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 0.5383244984595063\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 0.4512173618319668\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 0.5288248812146199\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 0.48694038334526596\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 0.5243774953553134\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 0.4486965354107603\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 0.5306078676524979\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 0.44735777038562147\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 0.5166814295989474\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 0.4828224548056156\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 0.5209291350963475\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 0.4437873484213141\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 262.5589624444644 minutes\n"
     ]
    }
   ],
   "source": [
    "train(model_scratch, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_scratch, 100, writer, \n",
    "                 PATH, False, None, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd00d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 85 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, model_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335ab5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 4.20 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0153121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 25.06 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "414692d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 9.46 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c750e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 4.59 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, model_scratch, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca31be2",
   "metadata": {},
   "source": [
    "# TODO Compared with from scratch adversarial training and attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9addb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "net_scratch_adv = copy.deepcopy(model_scratch) #am I doing correct? \n",
    "# for param in net_adv.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f7465c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = net_scratch_adv.parameters()\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net_scratch_adv.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = './cifar_trans_resnet_scratch_adv_pgd.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_trans_resnet_scratch_PGD\")\n",
    "pgd_attack = generate_adv(net_scratch_adv, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045da609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n",
      "Epoch [1/100]\t Training Loss: 2.0469779568864865\t lr: 0.001\n",
      "Epoch [1/100]\t Validation Loss: 12.82632237446459\t lr: 0.001\n",
      "Epoch [1/100]\t\n",
      "Epoch [2/100]\t Training Loss: 1.7371841123341905\t lr: 0.001\n",
      "Epoch [2/100]\t Validation Loss: 26.673698908166042\t lr: 0.001\n",
      "Epoch [2/100]\t\n",
      "Epoch [3/100]\t Training Loss: 1.6720261217078285\t lr: 0.001\n",
      "Epoch [3/100]\t Validation Loss: 13.963512686234486\t lr: 0.001\n",
      "Epoch [3/100]\t\n",
      "Epoch [4/100]\t Training Loss: 1.629674499297081\t lr: 0.001\n",
      "Epoch [4/100]\t Validation Loss: 12.616864958895913\t lr: 0.001\n",
      "Epoch [4/100]\t\n",
      "Epoch [5/100]\t Training Loss: 1.6080426020390541\t lr: 0.001\n",
      "Epoch [5/100]\t Validation Loss: 15.755662688726112\t lr: 0.001\n",
      "Epoch [5/100]\t\n",
      "Epoch [6/100]\t Training Loss: 1.5803513456793392\t lr: 0.001\n",
      "Epoch [6/100]\t Validation Loss: 17.246170913116842\t lr: 0.001\n",
      "Epoch [6/100]\t\n",
      "Epoch [7/100]\t Training Loss: 1.5713662128619221\t lr: 0.001\n",
      "Epoch [7/100]\t Validation Loss: 11.563516133948218\t lr: 0.001\n",
      "Epoch [7/100]\t\n",
      "Epoch [8/100]\t Training Loss: 1.5542269615870912\t lr: 0.001\n",
      "Epoch [8/100]\t Validation Loss: 25.169751686385915\t lr: 0.001\n",
      "Epoch [8/100]\t\n",
      "Epoch [9/100]\t Training Loss: 1.5371309805404194\t lr: 0.001\n",
      "Epoch [9/100]\t Validation Loss: 18.00045416626749\t lr: 0.001\n",
      "Epoch [9/100]\t\n",
      "Epoch [10/100]\t Training Loss: 1.5248412000553688\t lr: 0.001\n",
      "Epoch [10/100]\t Validation Loss: 9.933075675481483\t lr: 0.001\n",
      "Epoch [10/100]\t\n",
      "Epoch [11/100]\t Training Loss: 1.5219568059877362\t lr: 0.001\n",
      "Epoch [11/100]\t Validation Loss: 12.513286288780503\t lr: 0.001\n",
      "Epoch [11/100]\t\n",
      "Epoch [12/100]\t Training Loss: 1.512779692554718\t lr: 0.001\n",
      "Epoch [12/100]\t Validation Loss: 10.740938609159446\t lr: 0.001\n",
      "Epoch [12/100]\t\n",
      "Epoch [13/100]\t Training Loss: 1.4978940288733948\t lr: 0.001\n",
      "Epoch [13/100]\t Validation Loss: 14.037719811065287\t lr: 0.001\n",
      "Epoch [13/100]\t\n",
      "Epoch [14/100]\t Training Loss: 1.4946910929496942\t lr: 0.001\n",
      "Epoch [14/100]\t Validation Loss: 14.033028300804428\t lr: 0.001\n",
      "Epoch [14/100]\t\n",
      "Epoch [15/100]\t Training Loss: 1.4851338976179547\t lr: 0.001\n",
      "Epoch [15/100]\t Validation Loss: 14.736797308620018\t lr: 0.001\n",
      "Epoch [15/100]\t\n",
      "Epoch [16/100]\t Training Loss: 1.4864434131880855\t lr: 0.001\n",
      "Epoch [16/100]\t Validation Loss: 16.07994143570526\t lr: 0.001\n",
      "Epoch [16/100]\t\n",
      "Epoch [17/100]\t Training Loss: 1.4739186394854884\t lr: 0.001\n",
      "Epoch [17/100]\t Validation Loss: 12.953393079057525\t lr: 0.001\n",
      "Epoch [17/100]\t\n",
      "Epoch [18/100]\t Training Loss: 1.4655804701168518\t lr: 0.001\n",
      "Epoch [18/100]\t Validation Loss: 21.62583587743059\t lr: 0.001\n",
      "Epoch [18/100]\t\n",
      "Epoch [19/100]\t Training Loss: 1.46361746263626\t lr: 0.001\n",
      "Epoch [19/100]\t Validation Loss: 28.140568672856197\t lr: 0.001\n",
      "Epoch [19/100]\t\n",
      "Epoch [20/100]\t Training Loss: 1.451263535053224\t lr: 0.001\n",
      "Epoch [20/100]\t Validation Loss: 16.22090462793278\t lr: 0.001\n",
      "Epoch [20/100]\t\n",
      "Epoch [21/100]\t Training Loss: 1.4503140455621588\t lr: 0.001\n",
      "Epoch [21/100]\t Validation Loss: 21.477410087102577\t lr: 0.001\n",
      "Epoch [21/100]\t\n",
      "Epoch [22/100]\t Training Loss: 1.4437875534262499\t lr: 0.001\n",
      "Epoch [22/100]\t Validation Loss: 21.66397130942043\t lr: 0.001\n",
      "Epoch [22/100]\t\n",
      "Epoch [26/100]\t Training Loss: 1.42790734981332\t lr: 0.001\n",
      "Epoch [26/100]\t Validation Loss: 21.59221396868742\t lr: 0.001\n",
      "Epoch [26/100]\t\n",
      "Epoch [27/100]\t Training Loss: 1.4250945236981678\t lr: 0.001\n",
      "Epoch [27/100]\t Validation Loss: 21.064514256730863\t lr: 0.001\n",
      "Epoch [27/100]\t\n",
      "Epoch [28/100]\t Training Loss: 1.4236029718842957\t lr: 0.001\n",
      "Epoch [28/100]\t Validation Loss: 21.333262093459503\t lr: 0.001\n",
      "Epoch [28/100]\t\n",
      "Epoch [29/100]\t Training Loss: 1.4127750729051087\t lr: 0.001\n",
      "Epoch [29/100]\t Validation Loss: 20.124206373963176\t lr: 0.001\n",
      "Epoch [29/100]\t\n",
      "Epoch [30/100]\t Training Loss: 1.4098088616300422\t lr: 0.001\n",
      "Epoch [30/100]\t Validation Loss: 23.30897932414767\t lr: 0.001\n",
      "Epoch [30/100]\t\n",
      "Epoch [31/100]\t Training Loss: 1.4101243016055174\t lr: 0.001\n",
      "Epoch [31/100]\t Validation Loss: 19.08912562116792\t lr: 0.001\n",
      "Epoch [31/100]\t\n",
      "Epoch [32/100]\t Training Loss: 1.407431389364745\t lr: 0.001\n",
      "Epoch [32/100]\t Validation Loss: 31.062826180759863\t lr: 0.001\n",
      "Epoch [32/100]\t\n",
      "Epoch [33/100]\t Training Loss: 1.4031708789298603\t lr: 0.001\n",
      "Epoch [33/100]\t Validation Loss: 21.499856659128696\t lr: 0.001\n",
      "Epoch [33/100]\t\n",
      "Epoch [34/100]\t Training Loss: 1.3977193131166346\t lr: 0.001\n",
      "Epoch [34/100]\t Validation Loss: 30.65035549598404\t lr: 0.001\n",
      "Epoch [34/100]\t\n",
      "Epoch [35/100]\t Training Loss: 1.396104296454993\t lr: 0.001\n",
      "Epoch [35/100]\t Validation Loss: 34.95632900769198\t lr: 0.001\n",
      "Epoch [35/100]\t\n",
      "Epoch [36/100]\t Training Loss: 1.3938972263994729\t lr: 0.001\n",
      "Epoch [36/100]\t Validation Loss: 28.2003123367889\t lr: 0.001\n",
      "Epoch [36/100]\t\n",
      "Epoch [37/100]\t Training Loss: 1.3779588867636288\t lr: 0.001\n",
      "Epoch [37/100]\t Validation Loss: 25.056521282920354\t lr: 0.001\n",
      "Epoch [37/100]\t\n",
      "Epoch [38/100]\t Training Loss: 1.3857388792135525\t lr: 0.001\n",
      "Epoch [38/100]\t Validation Loss: 30.485150373434717\t lr: 0.001\n",
      "Epoch [38/100]\t\n",
      "Epoch [39/100]\t Training Loss: 1.3787288056005298\t lr: 0.001\n",
      "Epoch [39/100]\t Validation Loss: 31.928066881397104\t lr: 0.001\n",
      "Epoch [39/100]\t\n",
      "Epoch [40/100]\t Training Loss: 1.3747586066765554\t lr: 0.001\n",
      "Epoch [40/100]\t Validation Loss: 35.598667434499234\t lr: 0.001\n",
      "Epoch [40/100]\t\n",
      "Epoch [41/100]\t Training Loss: 1.3810983481614485\t lr: 0.001\n",
      "Epoch [41/100]\t Validation Loss: 26.891326252418228\t lr: 0.001\n",
      "Epoch [41/100]\t\n",
      "Epoch [42/100]\t Training Loss: 1.3797719692025343\t lr: 0.001\n",
      "Epoch [42/100]\t Validation Loss: 23.817816577380217\t lr: 0.001\n",
      "Epoch [42/100]\t\n",
      "Epoch [43/100]\t Training Loss: 1.3663002706854546\t lr: 0.001\n",
      "Epoch [43/100]\t Validation Loss: 35.270161882231506\t lr: 0.001\n",
      "Epoch [43/100]\t\n",
      "Epoch [44/100]\t Training Loss: 1.3657145494085443\t lr: 0.001\n",
      "Epoch [44/100]\t Validation Loss: 38.75579708437376\t lr: 0.001\n",
      "Epoch [44/100]\t\n",
      "Epoch [45/100]\t Training Loss: 1.3651254869178129\t lr: 0.001\n",
      "Epoch [45/100]\t Validation Loss: 36.21996510179737\t lr: 0.001\n",
      "Epoch [45/100]\t\n",
      "Epoch [46/100]\t Training Loss: 1.358974676912703\t lr: 0.001\n",
      "Epoch [46/100]\t Validation Loss: 36.14183148251304\t lr: 0.001\n",
      "Epoch [46/100]\t\n",
      "Epoch [47/100]\t Training Loss: 1.3584498728022856\t lr: 0.001\n",
      "Epoch [47/100]\t Validation Loss: 37.21391791331617\t lr: 0.001\n",
      "Epoch [47/100]\t\n",
      "Epoch [48/100]\t Training Loss: 1.3556007683429572\t lr: 0.001\n",
      "Epoch [48/100]\t Validation Loss: 37.468882114072386\t lr: 0.001\n",
      "Epoch [48/100]\t\n",
      "Epoch [49/100]\t Training Loss: 1.3540764726946115\t lr: 0.001\n",
      "Epoch [49/100]\t Validation Loss: 32.739949359169486\t lr: 0.001\n",
      "Epoch [49/100]\t\n",
      "Epoch [50/100]\t Training Loss: 1.3510549620289327\t lr: 0.001\n",
      "Epoch [50/100]\t Validation Loss: 34.85499181626718\t lr: 0.001\n",
      "Epoch [50/100]\t\n",
      "Epoch [51/100]\t Training Loss: 1.3491665356604339\t lr: 0.001\n",
      "Epoch [51/100]\t Validation Loss: 31.62392220316054\t lr: 0.001\n",
      "Epoch [51/100]\t\n",
      "Epoch [52/100]\t Training Loss: 1.340173334111948\t lr: 0.001\n",
      "Epoch [52/100]\t Validation Loss: 30.271266237089904\t lr: 0.001\n",
      "Epoch [52/100]\t\n",
      "Epoch [53/100]\t Training Loss: 1.345551182851767\t lr: 0.001\n",
      "Epoch [53/100]\t Validation Loss: 33.49459768850592\t lr: 0.001\n",
      "Epoch [53/100]\t\n",
      "Epoch [54/100]\t Training Loss: 1.3412454308146406\t lr: 0.001\n",
      "Epoch [54/100]\t Validation Loss: 29.259923403776146\t lr: 0.001\n",
      "Epoch [54/100]\t\n",
      "Epoch [55/100]\t Training Loss: 1.3307916584527095\t lr: 0.001\n",
      "Epoch [55/100]\t Validation Loss: 29.999857238576382\t lr: 0.001\n",
      "Epoch [55/100]\t\n",
      "Epoch [56/100]\t Training Loss: 1.3366077165774373\t lr: 0.001\n",
      "Epoch [56/100]\t Validation Loss: 35.163065029095996\t lr: 0.001\n",
      "Epoch [56/100]\t\n",
      "Epoch [57/100]\t Training Loss: 1.3312394957408271\t lr: 0.001\n",
      "Epoch [57/100]\t Validation Loss: 39.16292183308662\t lr: 0.001\n",
      "Epoch [57/100]\t\n",
      "Epoch [58/100]\t Training Loss: 1.3276511766111758\t lr: 0.001\n",
      "Epoch [58/100]\t Validation Loss: 33.355593234677855\t lr: 0.001\n",
      "Epoch [58/100]\t\n",
      "Epoch [59/100]\t Training Loss: 1.325469474658332\t lr: 0.001\n",
      "Epoch [59/100]\t Validation Loss: 43.1395796763746\t lr: 0.001\n",
      "Epoch [59/100]\t\n",
      "Epoch [60/100]\t Training Loss: 1.3254223897329072\t lr: 0.001\n",
      "Epoch [60/100]\t Validation Loss: 43.69859941699837\t lr: 0.001\n",
      "Epoch [60/100]\t\n",
      "Epoch [61/100]\t Training Loss: 1.3227926825013612\t lr: 0.001\n",
      "Epoch [61/100]\t Validation Loss: 43.37802027448823\t lr: 0.001\n",
      "Epoch [61/100]\t\n",
      "Epoch [62/100]\t Training Loss: 1.3229998386729405\t lr: 0.001\n",
      "Epoch [62/100]\t Validation Loss: 41.13771617261669\t lr: 0.001\n",
      "Epoch [62/100]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]\t Training Loss: 1.3129097150109919\t lr: 0.001\n",
      "Epoch [63/100]\t Validation Loss: 46.63334095628956\t lr: 0.001\n",
      "Epoch [63/100]\t\n",
      "Epoch [64/100]\t Training Loss: 1.3133342750846881\t lr: 0.001\n",
      "Epoch [64/100]\t Validation Loss: 47.947365917736974\t lr: 0.001\n",
      "Epoch [64/100]\t\n",
      "Epoch [65/100]\t Training Loss: 1.3118542792547085\t lr: 0.001\n",
      "Epoch [65/100]\t Validation Loss: 42.16519580309904\t lr: 0.001\n",
      "Epoch [65/100]\t\n",
      "Epoch [66/100]\t Training Loss: 1.3070138555658444\t lr: 0.001\n",
      "Epoch [66/100]\t Validation Loss: 43.04703598988207\t lr: 0.001\n",
      "Epoch [66/100]\t\n",
      "Epoch [67/100]\t Training Loss: 1.3066618143749968\t lr: 0.001\n",
      "Epoch [67/100]\t Validation Loss: 44.80973444105704\t lr: 0.001\n",
      "Epoch [67/100]\t\n",
      "Epoch [68/100]\t Training Loss: 1.29853588083516\t lr: 0.001\n",
      "Epoch [68/100]\t Validation Loss: 50.18283187286763\t lr: 0.001\n",
      "Epoch [68/100]\t\n",
      "Epoch [69/100]\t Training Loss: 1.3007290512704484\t lr: 0.001\n",
      "Epoch [69/100]\t Validation Loss: 45.95871411094183\t lr: 0.001\n",
      "Epoch [69/100]\t\n",
      "Epoch [70/100]\t Training Loss: 1.2998127833656643\t lr: 0.001\n",
      "Epoch [70/100]\t Validation Loss: 39.33275766010526\t lr: 0.001\n",
      "Epoch [70/100]\t\n",
      "Epoch [71/100]\t Training Loss: 1.3052153044649402\t lr: 0.001\n",
      "Epoch [71/100]\t Validation Loss: 41.9725490521781\t lr: 0.001\n",
      "Epoch [71/100]\t\n",
      "Epoch [72/100]\t Training Loss: 1.3014172391818308\t lr: 0.001\n",
      "Epoch [72/100]\t Validation Loss: 41.13960922820659\t lr: 0.001\n",
      "Epoch [72/100]\t\n",
      "Epoch [73/100]\t Training Loss: 1.292482666957104\t lr: 0.001\n",
      "Epoch [73/100]\t Validation Loss: 41.003978053225744\t lr: 0.001\n",
      "Epoch [73/100]\t\n",
      "Epoch [74/100]\t Training Loss: 1.3023228663617692\t lr: 0.001\n",
      "Epoch [74/100]\t Validation Loss: 41.28880773616743\t lr: 0.001\n",
      "Epoch [74/100]\t\n",
      "Epoch [75/100]\t Training Loss: 1.2892892825633973\t lr: 0.001\n",
      "Epoch [75/100]\t Validation Loss: 47.66694650770743\t lr: 0.001\n",
      "Epoch [75/100]\t\n",
      "Epoch [76/100]\t Training Loss: 1.293273857182554\t lr: 0.001\n",
      "Epoch [76/100]\t Validation Loss: 43.215559271317495\t lr: 0.001\n",
      "Epoch [76/100]\t\n",
      "Epoch [77/100]\t Training Loss: 1.292486616412697\t lr: 0.001\n",
      "Epoch [77/100]\t Validation Loss: 37.0839307519454\t lr: 0.001\n",
      "Epoch [77/100]\t\n",
      "Epoch [78/100]\t Training Loss: 1.2860276013079202\t lr: 0.001\n",
      "Epoch [78/100]\t Validation Loss: 41.12446613553204\t lr: 0.001\n",
      "Epoch [78/100]\t\n",
      "Epoch [79/100]\t Training Loss: 1.2895736592200102\t lr: 0.001\n",
      "Epoch [79/100]\t Validation Loss: 42.577222027356115\t lr: 0.001\n",
      "Epoch [79/100]\t\n",
      "Epoch [80/100]\t Training Loss: 1.2814486162436893\t lr: 0.001\n",
      "Epoch [80/100]\t Validation Loss: 44.78114917610265\t lr: 0.001\n",
      "Epoch [80/100]\t\n",
      "Epoch [81/100]\t Training Loss: 1.2794039322592108\t lr: 0.001\n",
      "Epoch [81/100]\t Validation Loss: 40.38455540620828\t lr: 0.001\n",
      "Epoch [81/100]\t\n",
      "Epoch [82/100]\t Training Loss: 1.2763364485767492\t lr: 0.001\n",
      "Epoch [82/100]\t Validation Loss: 41.38713836669922\t lr: 0.001\n",
      "Epoch [82/100]\t\n",
      "Epoch [83/100]\t Training Loss: 1.2742911345513581\t lr: 0.001\n",
      "Epoch [83/100]\t Validation Loss: 42.69137071054193\t lr: 0.001\n",
      "Epoch [83/100]\t\n",
      "Epoch [84/100]\t Training Loss: 1.266189426717246\t lr: 0.001\n",
      "Epoch [84/100]\t Validation Loss: 47.808435415919824\t lr: 0.001\n",
      "Epoch [84/100]\t\n",
      "Epoch [85/100]\t Training Loss: 1.2728576279052384\t lr: 0.001\n",
      "Epoch [85/100]\t Validation Loss: 47.90170568152319\t lr: 0.001\n",
      "Epoch [85/100]\t\n",
      "Epoch [86/100]\t Training Loss: 1.2700804546665962\t lr: 0.001\n",
      "Epoch [86/100]\t Validation Loss: 52.57911479322216\t lr: 0.001\n",
      "Epoch [86/100]\t\n",
      "Epoch [87/100]\t Training Loss: 1.264673232270019\t lr: 0.001\n",
      "Epoch [87/100]\t Validation Loss: 55.887574304508256\t lr: 0.001\n",
      "Epoch [87/100]\t\n",
      "Epoch [88/100]\t Training Loss: 1.2643084806554459\t lr: 0.001\n",
      "Epoch [88/100]\t Validation Loss: 55.630084315432775\t lr: 0.001\n",
      "Epoch [88/100]\t\n",
      "Epoch [89/100]\t Training Loss: 1.2625198548712084\t lr: 0.001\n",
      "Epoch [89/100]\t Validation Loss: 45.0898909749864\t lr: 0.001\n",
      "Epoch [89/100]\t\n",
      "Epoch [90/100]\t Training Loss: 1.2547012683375718\t lr: 0.001\n",
      "Epoch [90/100]\t Validation Loss: 42.58589435529105\t lr: 0.001\n",
      "Epoch [90/100]\t\n",
      "Epoch [91/100]\t Training Loss: 1.26066436913922\t lr: 0.001\n",
      "Epoch [91/100]\t Validation Loss: 44.016259736652614\t lr: 0.001\n",
      "Epoch [91/100]\t\n",
      "Epoch [92/100]\t Training Loss: 1.2561428395988385\t lr: 0.001\n",
      "Epoch [92/100]\t Validation Loss: 56.932435530650466\t lr: 0.001\n",
      "Epoch [92/100]\t\n",
      "Epoch [93/100]\t Training Loss: 1.252544674117242\t lr: 0.001\n",
      "Epoch [93/100]\t Validation Loss: 46.4109294987932\t lr: 0.001\n",
      "Epoch [93/100]\t\n",
      "Epoch [94/100]\t Training Loss: 1.2536997712786546\t lr: 0.001\n",
      "Epoch [94/100]\t Validation Loss: 39.45154631892337\t lr: 0.001\n",
      "Epoch [94/100]\t\n",
      "Epoch [95/100]\t Training Loss: 1.2536902055715966\t lr: 0.001\n",
      "Epoch [95/100]\t Validation Loss: 51.66116410267504\t lr: 0.001\n",
      "Epoch [95/100]\t\n",
      "Epoch [96/100]\t Training Loss: 1.2440000531618551\t lr: 0.001\n",
      "Epoch [96/100]\t Validation Loss: 50.1507467438903\t lr: 0.001\n",
      "Epoch [96/100]\t\n",
      "Epoch [97/100]\t Training Loss: 1.250293677267821\t lr: 0.001\n",
      "Epoch [97/100]\t Validation Loss: 53.11343876319596\t lr: 0.001\n",
      "Epoch [97/100]\t\n",
      "Epoch [98/100]\t Training Loss: 1.2477165799006782\t lr: 0.001\n",
      "Epoch [98/100]\t Validation Loss: 49.079926889153974\t lr: 0.001\n",
      "Epoch [98/100]\t\n",
      "Epoch [99/100]\t Training Loss: 1.2463895012350643\t lr: 0.001\n",
      "Epoch [99/100]\t Validation Loss: 52.03522443167771\t lr: 0.001\n",
      "Epoch [99/100]\t\n",
      "Epoch [100/100]\t Training Loss: 1.245223818227763\t lr: 0.001\n",
      "Epoch [100/100]\t Validation Loss: 52.62372328359869\t lr: 0.001\n",
      "Epoch [99/100]\t Time Taken: 1472.07352420489 minutes\n"
     ]
    }
   ],
   "source": [
    "train(net_scratch_adv, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_adv, 100, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c84bfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, net_scratch_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0405fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 74.38 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca255b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 74.31 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98d7c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 74.03 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e540e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 74.00 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, net_scratch_adv, \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d11097",
   "metadata": {},
   "source": [
    "##### Prevent overfiting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5363b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = torch.load(\"./cifar_resnet_scratch.pt\")\n",
    "model_scratch = torch.load(\"./cifar_resnet_scratch.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0672bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50f57427",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24869/17115065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataset, val_dataset, train_loader, val_loader = CIFAR10(128, finetune = True, \n\u001b[0;32m----> 7\u001b[0;31m                                                                input_size = input_size, test_batch_size=128)\n\u001b[0m\u001b[1;32m      8\u001b[0m classes = ('plane', 'car', 'bird', 'cat',\n\u001b[1;32m      9\u001b[0m            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "source": [
    "# model_name = \"resnet\"\n",
    "# num_classes = 10\n",
    "# feature_extract = False\n",
    "\n",
    "\n",
    "# train_dataset, val_dataset, train_loader, val_loader = CIFAR10(128, finetune = True, \n",
    "#                                                                input_size = input_size, test_batch_size=128)\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b549368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 03:29:28.589432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 03:29:28.868745: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-17 03:29:29.950203: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-17 03:29:29.950379: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-12-17 03:29:29.950397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model_load.parameters()\n",
    "\n",
    "feature_extract = False\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_load.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_scratch.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adv = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "train_criterion = nn.CrossEntropyLoss()\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = './cifar_trans_resnet_scratch_adv_pgd_10.pth'\n",
    "device = \"cuda\"\n",
    "writer = SummaryWriter(\"Adv_trans_resnet_scratch_PGD_10\")\n",
    "pgd_attack = generate_adv(model_load, \"pgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6eca3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24869/1496941927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(model_load, train_loader, train_criterion, val_loader, val_criterion, \n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   n_steps_show=1000)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train(model_load, train_loader, train_criterion, val_loader, val_criterion, \n",
    "              optimizer_adv, 10, writer, \n",
    "                 PATH, True, pgd_attack, device=\"cuda\",\n",
    "                  n_steps_show=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c53b18a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the clean accuracy is \n",
      "Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    }
   ],
   "source": [
    "print(\"the clean accuracy is \")\n",
    "test(val_loader, model_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5aec8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD\n",
      "[Model loaded]\n",
      "Acc: 74.38 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"PGD\")\n",
    "pgd_attack_transfer = generate_adv(model_scratch, \"pgd\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "pgd_acc = test_attack(val_loader, pgd_attack_transfer, model_load, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9574311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm\n",
      "[Model loaded]\n",
      "Acc: 74.31 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"fgsm\")\n",
    "fgsm_attack_transfer = generate_adv(model_scratch, \"fgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "fgsm_acc = test_attack(val_loader, fgsm_attack_transfer, model_load, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adab64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifgsm\n",
      "[Model loaded]\n",
      "Acc: 74.03 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"nifgsm\")\n",
    "nifgsm_attack_transfer = generate_adv(model_scratch, \"nifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "nifgsm_acc = test_attack(val_loader, nifgsm_attack_transfer, model_load, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd0c195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmifgsm\n",
      "[Model loaded]\n",
      "Acc: 74.00 %\n",
      "adv model\n"
     ]
    }
   ],
   "source": [
    "print(\"vmifgsm\")\n",
    "vmifgsm_attack_transfer = generate_adv(model_scratch, \"vmifgsm\")\n",
    "# pgd_attack_transfer = pgd_attack_transfer.cpu()\n",
    "\n",
    "vmifgsm_acc = test_attack(val_loader, vmifgsm_attack_transfer, model_load, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9a545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
